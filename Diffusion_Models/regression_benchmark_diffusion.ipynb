{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3770,"status":"ok","timestamp":1735594469733,"user":{"displayName":"Oliver Fritsche","userId":"15171898326940313848"},"user_tz":300},"id":"YkI_GtjaTfqd","outputId":"3b708ff6-eb4c-4834-ed48-68d0aa5e50c0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/MyDrive; to attempt to forcibly remount, call drive.mount(\"/content/MyDrive\", force_remount=True).\n"]}],"source":["\n","#mount drive\n","from google.colab import drive\n","drive.mount('/content/MyDrive')\n","import seaborn as sns\n","sns.set_theme(\"paper\")\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ETk_LSRPvM--","executionInfo":{"status":"ok","timestamp":1735594473493,"user_tz":300,"elapsed":3763,"user":{"displayName":"Oliver Fritsche","userId":"15171898326940313848"}}},"outputs":[],"source":["# @title Initialize Config\n","\n","import torch\n","import numpy\n","class Config:\n","    def __init__(self, **kwargs):\n","        self.channels_imu_acc = kwargs.get('channels_imu_acc', [])\n","        self.channels_imu_gyr = kwargs.get('channels_imu_gyr', [])\n","        self.channels_joints = kwargs.get('channels_joints', [])\n","        self.channels_emg = kwargs.get('channels_emg', [])\n","        self.seed = kwargs.get('seed', 42)\n","        self.data_folder_name = kwargs.get('data_folder_name', 'default_data_folder_name')\n","        self.dataset_root = kwargs.get('dataset_root', 'default_dataset_root')\n","        self.imu_transforms = kwargs.get('imu_transforms', [])\n","        self.joint_transforms = kwargs.get('joint_transforms', [])\n","        self.emg_transforms = kwargs.get('emg_transforms', [])\n","        self.input_format = kwargs.get('input_format', 'csv')\n","\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","config = Config(\n","    data_folder_name='/content/MyDrive/MyDrive/sd_datacollection_v4/all_subjects_data_final.h5',\n","    dataset_root='/content/datasets',\n","    input_format=\"csv\",\n","    channels_imu_acc=['ACCX1', 'ACCY1', 'ACCZ1','ACCX2', 'ACCY2', 'ACCZ2', 'ACCX3', 'ACCY3', 'ACCZ3', 'ACCX4', 'ACCY4', 'ACCZ4', 'ACCX5', 'ACCY5', 'ACCZ5', 'ACCX6', 'ACCY6', 'ACCZ6'],\n","    channels_imu_gyr=['GYROX1', 'GYROY1', 'GYROZ1', 'GYROX2', 'GYROY2', 'GYROZ2', 'GYROX3', 'GYROY3', 'GYROZ3', 'GYROX4', 'GYROY4', 'GYROZ4', 'GYROX5', 'GYROY5', 'GYROZ5', 'GYROX6', 'GYROY6', 'GYROZ6'],\n","    channels_joints=['elbow_flex_r', 'arm_flex_r', 'arm_add_r'],\n","    channels_emg=['IM EMG4', 'IM EMG5', 'IM EMG6'],\n",")\n","\n","#set seeds\n","torch.manual_seed(config.seed)\n","numpy.random.seed(config.seed)\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"yvI4iVwAvg7y","executionInfo":{"status":"ok","timestamp":1735594473494,"user_tz":300,"elapsed":6,"user":{"displayName":"Oliver Fritsche","userId":"15171898326940313848"}}},"outputs":[],"source":["class DataSharder:\n","    def __init__(self, config, split):\n","        self.config = config\n","        self.h5_file_path = config.data_folder_name  # Path to the HDF5 file\n","        self.split = split\n","\n","    def load_data(self, subjects, window_length, window_overlap, dataset_name):\n","        print(f\"Processing subjects: {subjects} with window length: {window_length}, overlap: {window_overlap}\")\n","\n","        self.window_length = window_length\n","        self.window_overlap = window_overlap\n","\n","        # Process the data from the HDF5 file\n","        self._process_and_save_patients_h5(subjects, dataset_name)\n","\n","    def _process_and_save_patients_h5(self, subjects, dataset_name):\n","        # Open the HDF5 file\n","        with h5py.File(self.h5_file_path, 'r') as h5_file:\n","            dataset_folder = os.path.join(self.config.dataset_root, dataset_name, self.split).replace(\"subject\", \"\").replace(\"__\", \"_\")\n","            print(\"Dataset folder:\", dataset_folder)\n","\n","            if os.path.exists(dataset_folder):\n","                print(\"Dataset Exists, Skipping...\")\n","                return\n","\n","            os.makedirs(dataset_folder, exist_ok=True)\n","            print(\"Dataset folder created: \", dataset_folder)\n","\n","            for subject_id in tqdm(subjects, desc=\"Processing subjects\"):\n","                subject_key = subject_id\n","                if subject_key not in h5_file:\n","                    print(f\"Subject {subject_key} not found in the HDF5 file. Skipping.\")\n","                    continue\n","\n","                subject_data = h5_file[subject_key]\n","                session_keys = list(subject_data.keys())  # Sessions for this subject\n","\n","                for session_id in session_keys:\n","                    session_data_group = subject_data[session_id]\n","\n","                    for sessions_speed in session_data_group.keys():\n","                        session_data = session_data_group[sessions_speed]\n","\n","                        # Extract IMU, EMG, and Joint data as numpy arrays\n","                        imu_data, imu_columns = self._extract_channel_data(session_data, self.config.channels_imu_acc + self.config.channels_imu_gyr)\n","                        emg_data, emg_columns = self._extract_channel_data(session_data, self.config.channels_emg)\n","                        joint_data, joint_columns = self._extract_channel_data(session_data, self.config.channels_joints)\n","\n","                        # Shard the data into windows and save each window\n","                        self._save_windowed_data(imu_data, emg_data, joint_data, subject_key, session_id,sessions_speed, dataset_folder, imu_columns, emg_columns, joint_columns)\n","\n","    def _save_windowed_data(self, imu_data, emg_data, joint_data, subject_key, session_id, session_speed, dataset_folder, imu_columns, emg_columns, joint_columns):\n","        window_size = self.window_length\n","        overlap = self.window_overlap\n","        step_size = window_size - overlap\n","\n","        # Path to the CSV log file\n","        csv_file_path = os.path.join(dataset_folder, '..', f\"{self.split}_info.csv\")\n","\n","        # Ensure the folder exists\n","        os.makedirs(dataset_folder, exist_ok=True)\n","\n","        # Prepare CSV log headers (ensure the columns are 'file_name' and 'file_path')\n","        csv_headers = ['file_name', 'file_path']\n","\n","        # Create or append to the CSV log file\n","        file_exists = os.path.isfile(csv_file_path)\n","        with open(csv_file_path, mode='a', newline='') as csv_file:\n","            writer = csv.writer(csv_file)\n","\n","            # Write the headers only if the file is new\n","            if not file_exists:\n","                writer.writerow(csv_headers)\n","\n","            # Determine the total data length based on the minimum length across the data sources\n","            total_data_length = min(imu_data.shape[1], emg_data.shape[1], joint_data.shape[1])\n","\n","            # Adjust the starting point for windows based on total data length\n","            start = 2000 if total_data_length > 4000 else 0\n","\n","            # Ensure that each window across imu_data, emg_data, and joint_data has the same shape before concatenation\n","            for i in range(start, total_data_length - window_size + 1, step_size):\n","                imu_window = imu_data[:, i:i + window_size]\n","                emg_window = emg_data[:, i:i + window_size]\n","                joint_window = joint_data[:, i:i + window_size]\n","\n","                # Check if the window sizes are valid\n","                if imu_window.shape[1] == window_size and emg_window.shape[1] == window_size and joint_window.shape[1] == window_size:\n","                    # Convert windowed data to pandas DataFrame\n","\n","\n","\n","                    imu_df = pd.DataFrame(imu_window.T, columns=imu_columns)\n","                    emg_df = pd.DataFrame(emg_window.T, columns=emg_columns)\n","                    joint_df = pd.DataFrame(joint_window.T, columns=joint_columns)\n","\n","\n","\n","                    # Concatenate the data along the column axis\n","                    combined_df = pd.concat([imu_df, emg_df, joint_df], axis=1)\n","\n","                    # Save the combined windowed data as a CSV file\n","                    file_name = f\"{subject_key}_{session_id}_{session_speed}_win_{i}_ws{window_size}_ol{overlap}.csv\"\n","                    file_path = os.path.join(dataset_folder, file_name)\n","                    combined_df.to_csv(file_path, index=False)\n","\n","                    # Log the file name and path in the CSV (in the correct columns)\n","                    writer.writerow([file_name, file_path])\n","                else:\n","                    print(f\"Skipping window {i} due to mismatched window sizes.\")\n","\n","    def _extract_channel_data(self, session_data, channels):\n","      extracted_data = []\n","      new_column_names = []  # Initialize here\n","\n","      if isinstance(session_data, h5py.Dataset):\n","          if session_data.dtype.names:\n","              # Compound dataset\n","              column_names = session_data.dtype.names\n","              for channel in channels:\n","                  if channel in column_names:\n","                      channel_data = session_data[channel][:]\n","                      channel_data = pd.to_numeric(channel_data, errors='coerce')\n","                      df = pd.DataFrame(channel_data)\n","                      df_interpolated = df.interpolate(method='linear', axis=0, limit_direction='both')\n","                      extracted_data.append(df_interpolated.to_numpy().flatten())\n","                      new_column_names.append(channel)  # Populate here\n","                  else:\n","                      print(f\"Channel {channel} not found in compound dataset.\")\n","          else:\n","              # Simple dataset\n","              column_names = list(session_data.attrs.get('column_names', []))\n","              assert len(column_names) > 0, \"column_names not found in dataset attributes\"\n","              for channel in channels:\n","                  if channel in column_names:\n","                      col_idx = column_names.index(channel)\n","                      channel_data = session_data[:, col_idx]\n","                      channel_data = pd.to_numeric(channel_data, errors='coerce')\n","                      df = pd.DataFrame(channel_data)\n","                      df_interpolated = df.interpolate(method='linear', axis=0, limit_direction='both')\n","                      extracted_data.append(df_interpolated.to_numpy().flatten())\n","                      new_column_names.append(channel)\n","                  else:\n","                      print(f\"Channel {channel} not found in session data.\")\n","\n","      return np.array(extracted_data), new_column_names\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"uCr-VlFC8Nu7","executionInfo":{"status":"ok","timestamp":1735594474529,"user_tz":300,"elapsed":1039,"user":{"displayName":"Oliver Fritsche","userId":"15171898326940313848"}}},"outputs":[],"source":["# @title Dataset creation\n","from torch.utils.data import Dataset, DataLoader\n","from torch.utils.data import random_split\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA\n","from torch.utils.data import ConcatDataset\n","import random\n","from torch.utils.data import TensorDataset\n","\n","class ImuJointPairDataset(Dataset):\n","    def __init__(self, config, subjects, window_length, window_overlap, split='train', dataset_train_name='train', dataset_test_name='test'):\n","        self.config = config\n","        self.split = split\n","        self.subjects = subjects\n","        self.window_length = window_length\n","        self.window_overlap = window_overlap if split == 'train' else 0\n","        self.input_format = config.input_format\n","        self.channels_imu_acc = config.channels_imu_acc\n","        self.channels_imu_gyr = config.channels_imu_gyr\n","        self.channels_joints = config.channels_joints\n","        self.channels_emg = config.channels_emg\n","\n","        # Convert the list of subjects to a string that is path-safe\n","        subjects_str = \"_\".join(map(str, subjects)).replace('subject', '').replace('__', '_')\n","\n","        # Use dataset_train_name or dataset_test_name based on split\n","        if split == 'train':\n","            dataset_name = f\"dataset_wl{self.window_length}_ol{self.window_overlap}_train{subjects_str}\"\n","        else:\n","            dataset_name = f\"dataset_wl{self.window_length}_ol{self.window_overlap}_test{subjects_str}\"\n","\n","        self.dataset_name = dataset_name\n","\n","        # Define the root directory based on dataset name\n","        self.root_dir = os.path.join(self.config.dataset_root, self.dataset_name)\n","\n","        # Ensure sharded data exists, if not, reshard\n","        self.ensure_resharded(subjects, dataset_train_name if split == 'train' else dataset_test_name)\n","\n","        info_path = os.path.join(self.root_dir, f\"{split}_info.csv\")\n","        self.data = pd.read_csv(info_path)\n","\n","    def ensure_resharded(self, subjects, dataset_name):\n","        if not os.path.exists(self.root_dir):\n","            print(f\"Sharded data not found at {self.root_dir}. Resharding...\")\n","            data_sharder = DataSharder(self.config,self.split)\n","            # Pass dynamic parameters to sharder\n","            data_sharder.load_data(subjects, window_length=self.window_length, window_overlap=self.window_overlap, dataset_name=self.dataset_name)\n","        else:\n","            print(f\"Sharded data found at {self.root_dir}. Skipping resharding.\")\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        file_path = os.path.join(self.root_dir,self.split, self.data.iloc[idx, 0])\n","\n","        if self.input_format == \"csv\":\n","            combined_data = pd.read_csv(file_path)\n","        else:\n","            raise ValueError(\"Unsupported input format: {}\".format(self.input_format))\n","\n","        imu_data_acc, imu_data_gyr, joint_data, emg_data = self._extract_and_transform(combined_data)\n","        return imu_data_acc, imu_data_gyr, joint_data, emg_data\n","\n","    def _extract_and_transform(self, combined_data):\n","        imu_data_acc = self._extract_channels(combined_data, self.channels_imu_acc)\n","        imu_data_gyr = self._extract_channels(combined_data, self.channels_imu_gyr)\n","        joint_data = self._extract_channels(combined_data, self.channels_joints)\n","        emg_data = self._extract_channels(combined_data, self.channels_emg)\n","\n","        imu_data_acc = self.apply_transforms(imu_data_acc, self.config.imu_transforms)\n","        imu_data_gyr = self.apply_transforms(imu_data_gyr, self.config.imu_transforms)\n","        joint_data = self.apply_transforms(joint_data, self.config.joint_transforms)\n","        emg_data = self.apply_transforms(emg_data, self.config.emg_transforms)\n","\n","        return imu_data_acc, imu_data_gyr, joint_data, emg_data\n","\n","    def _extract_channels(self, combined_data, channels):\n","        return combined_data[channels].values if self.input_format == \"csv\" else combined_data[:, channels]\n","\n","    def apply_transforms(self, data, transforms):\n","        for transform in transforms:\n","            data = transform(data)\n","        return torch.tensor(data, dtype=torch.float32)\n","\n","def create_base_data_loaders(\n","    config,\n","    train_subjects,\n","    test_subjects,\n","    window_length=100,\n","    window_overlap=75,\n","    batch_size=64,\n","    dataset_train_name='train',\n","    dataset_test_name='test'\n","):\n","    # Create datasets with explicit parameters\n","    train_dataset = ImuJointPairDataset(\n","        config=config,\n","        subjects=train_subjects,\n","        window_length=window_length,\n","        window_overlap=window_overlap,\n","        split='train',\n","        dataset_train_name=dataset_train_name\n","    )\n","\n","    test_dataset = ImuJointPairDataset(\n","        config=config,\n","        subjects=test_subjects,\n","        window_length=window_length,\n","        window_overlap=window_overlap,\n","        split='test',\n","        dataset_test_name=dataset_test_name\n","    )\n","\n","    # Split train dataset into training and validation sets\n","    train_size = int(0.9 * len(train_dataset))\n","    val_size = len(train_dataset) - train_size\n","    train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n","\n","    # Create data loaders\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","    return train_loader, val_loader, test_loader\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"oAsMzR7bSB5J","executionInfo":{"status":"ok","timestamp":1735594474529,"user_tz":300,"elapsed":15,"user":{"displayName":"Oliver Fritsche","userId":"15171898326940313848"}}},"outputs":[],"source":["# @title Kinematicsnet Architecture\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import time\n","from scipy.signal import butter, filtfilt\n","from sklearn.metrics import mean_squared_error\n","import numpy as np\n","class Encoder_1(nn.Module):\n","    def __init__(self, input_dim, dropout):\n","        super(Encoder_1, self).__init__()\n","        self.lstm_1 = nn.LSTM(input_dim, 128, bidirectional=True, batch_first=True, dropout=0)\n","        self.lstm_2 = nn.LSTM(256, 64, bidirectional=True, batch_first=True, dropout=0)\n","        self.flatten = nn.Flatten()\n","        self.fc = nn.Linear(128, 32)\n","        self.dropout_1 = nn.Dropout(dropout)\n","        self.dropout_2 = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        out_1, (h_1, _) = self.lstm_1(x)\n","        out_1 = self.dropout_1(out_1)\n","        out_2, (h_2, _) = self.lstm_2(out_1)\n","        out_2 = self.dropout_2(out_2)\n","        return out_2, (h_1, h_2)\n","\n","class Encoder_2(nn.Module):\n","    def __init__(self, input_dim, dropout):\n","        super(Encoder_2, self).__init__()\n","        self.gru_1 = nn.GRU(input_dim, 128, bidirectional=True, batch_first=True, dropout=0)\n","        self.gru_2 = nn.GRU(256, 64, bidirectional=True, batch_first=True, dropout=0)\n","        self.flatten = nn.Flatten()\n","        self.fc = nn.Linear(128, 32)\n","        self.dropout_1 = nn.Dropout(dropout)\n","        self.dropout_2 = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        out_1, h_1 = self.gru_1(x)\n","        out_1 = self.dropout_1(out_1)\n","        out_2, h_2 = self.gru_2(out_1)\n","        out_2 = self.dropout_2(out_2)\n","        return out_2, (h_1, h_2)\n","\n","\n","class GatingModule(nn.Module):\n","    def __init__(self, input_size):\n","        super(GatingModule, self).__init__()\n","        self.gate = nn.Sequential(\n","            nn.Linear(2*input_size, input_size),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, input1, input2):\n","        # Apply gating mechanism\n","        gate_output = self.gate(torch.cat((input1,input2),dim=-1))\n","\n","        # Scale the inputs based on the gate output\n","        gated_input1 = input1 * gate_output\n","        gated_input2 = input2 * (1 - gate_output)\n","\n","        # Combine the gated inputs\n","        output = gated_input1 + gated_input2\n","        return output\n","#variable w needs to be checked for correct value, stand-in value used\n","class teacher(nn.Module):\n","    def __init__(self, input_acc, input_gyr, input_emg, drop_prob=0.25, w=100):\n","        \"\"\"\n","        input_acc, input_gyr, input_emg: Dimensionalities per modality\n","        drop_prob: dropout probability\n","        w: sequence length processed by LSTM/GRU\n","        \"\"\"\n","        super(teacher, self).__init__()\n","        self.w = w\n","\n","        # ------------------\n","        # Encoders\n","        # ------------------\n","        self.encoder_1_acc = Encoder_1(input_acc, drop_prob)\n","        self.encoder_1_gyr = Encoder_1(input_gyr, drop_prob)\n","        self.encoder_1_emg = Encoder_1(input_emg, drop_prob)\n","\n","        self.encoder_2_acc = Encoder_2(input_acc, drop_prob)\n","        self.encoder_2_gyr = Encoder_2(input_gyr, drop_prob)\n","        self.encoder_2_emg = Encoder_2(input_emg, drop_prob)\n","\n","        # ------------------\n","        # BatchNorms\n","        # ------------------\n","        self.BN_acc = nn.BatchNorm1d(input_acc, affine=False)\n","        self.BN_gyr = nn.BatchNorm1d(input_gyr, affine=False)\n","        self.BN_emg = nn.BatchNorm1d(input_emg, affine=False)\n","\n","        # ------------------\n","        # Gating Modules\n","        # ------------------\n","        self.gate_1 = GatingModule(128)\n","        self.gate_2 = GatingModule(128)\n","        self.gate_3 = GatingModule(128)\n","\n","        # ------------------\n","        # Additional Layers\n","        # ------------------\n","        self.dropout = nn.Dropout(p=0.05)\n","        self.fc_kd = nn.Linear(3 * 128, 2 * 128)  # Some knowledge-distillation head\n","        self.weighted_feat = nn.Sequential(nn.Linear(128, 1), nn.Sigmoid())\n","        self.attention = nn.MultiheadAttention(3 * 128, 4, batch_first=True)\n","\n","        # Gating\n","        self.gating_net = nn.Sequential(\n","            nn.Linear(128 * 3, 3 * 128),\n","            nn.Sigmoid()\n","        )\n","        self.gating_net_1 = nn.Sequential(\n","            nn.Linear(2 * 3 * 128 + 128, 2 * 3 * 128 + 128),\n","            nn.Sigmoid()\n","        )\n","\n","        # Final output head: shape [batch, w, 3]\n","        # Interpreted as \"predicted noise\" for each modality dimension\n","        self.fc = nn.Linear(2 * 3 * 128 + 128, 3)\n","\n","    def forward(self, X_acc, X_gyr, X_emg, timestep):\n","        \"\"\"\n","        Predict noise.\n","        - X_acc, X_gyr, X_emg: [batch, seq_len, feat_dim] each\n","        - timestep: [batch, seq_len, 1] or broadcast shape,\n","                    we won't use it inside the LSTM/GRUs directly here,\n","                    but we keep the signature consistent with the snippet.\n","        Return: predicted noise, shape [batch, seq_len, 3]\n","        \"\"\"\n","        out, _, _ = self._base_forward(X_acc, X_gyr, X_emg)\n","        return out\n","\n","    def _base_forward(self, x_acc, x_gyr, x_emg):\n","        \"\"\"\n","        The core teacher architecture, originally returning (out, x_kd, hidden_states).\n","        We'll keep it intact. 'out' is used as the final predicted noise.\n","        \"\"\"\n","        # Flatten to [b*w, feats]\n","        b, w_, f_acc = x_acc.size()\n","        b2, w2_, f_gyr = x_gyr.size()\n","        b3, w3_, f_emg = x_emg.size()\n","\n","        x_acc_1 = x_acc.view(b * w_, f_acc)\n","        x_gyr_1 = x_gyr.view(b2 * w2_, f_gyr)\n","        x_emg_1 = x_emg.view(b3 * w3_, f_emg)\n","\n","        # ------------------\n","        # BatchNorm each\n","        # ------------------\n","        x_acc_1 = self.BN_acc(x_acc_1)\n","        x_gyr_1 = self.BN_gyr(x_gyr_1)\n","        x_emg_1 = self.BN_emg(x_emg_1)\n","\n","        # Reshape back\n","        x_acc_2 = x_acc_1.view(b, w_, f_acc)\n","        x_gyr_2 = x_gyr_1.view(b2, w2_, f_gyr)\n","        x_emg_2 = x_emg_1.view(b3, w3_, f_emg)\n","\n","        # ------------------\n","        # Encoder 1\n","        # ------------------\n","        x_acc_1, (h_acc_1, _) = self.encoder_1_acc(x_acc_2)\n","        x_gyr_1, (h_gyr_1, _) = self.encoder_1_gyr(x_gyr_2)\n","        x_emg_1, (h_emg_1, _) = self.encoder_1_emg(x_emg_2)\n","\n","        # ------------------\n","        # Encoder 2\n","        # ------------------\n","        x_acc_2, (h_acc_2, _) = self.encoder_2_acc(x_acc_2)\n","        x_gyr_2, (h_gyr_2, _) = self.encoder_2_gyr(x_gyr_2)\n","        x_emg_2, (h_emg_2, _) = self.encoder_2_emg(x_emg_2)\n","\n","        # ------------------\n","        # Gating\n","        # ------------------\n","        x_acc = self.gate_1(x_acc_1, x_acc_2)  # [b, w, 128]\n","        x_gyr = self.gate_2(x_gyr_1, x_gyr_2)\n","        x_emg = self.gate_3(x_emg_1, x_emg_2)\n","\n","        # Merge\n","        x = torch.cat((x_acc, x_gyr, x_emg), dim=-1)  # [b, w, 3*128]\n","        x_kd = self.fc_kd(x)  # [b, w, 2*128]\n","\n","        # Multihead Attention\n","        out_1, attn_weights = self.attention(x, x, x)  # [b, w, 3*128]\n","\n","        gating_weights = self.gating_net(x)\n","        out_2 = gating_weights * x\n","\n","        # Weighted features\n","        w1 = self.weighted_feat(x[:, :, :128])    # [b, w, 1]\n","        w2 = self.weighted_feat(x[:, :, 128:256]) # [b, w, 1]\n","        w3 = self.weighted_feat(x[:, :, 256:384]) # [b, w, 1]\n","\n","        x_1 = w1 * x[:, :, 0:128]\n","        x_2 = w2 * x[:, :, 128:256]\n","        x_3 = w3 * x[:, :, 256:384]\n","        out_3 = x_1 + x_2 + x_3\n","\n","        out = torch.cat((out_1, out_2, out_3), dim=-1)  # [b, w, 9*128]\n","        gating_weights_1 = self.gating_net_1(out)\n","        out = gating_weights_1 * out\n","\n","        # Final linear: produce shape [b, w, 3] = predicted noise\n","        out = self.fc(out)\n","        return out, x_kd, (h_acc_1, h_acc_2, h_gyr_1, h_gyr_2, h_emg_1, h_emg_2)\n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"wmdCuEysPimX","executionInfo":{"status":"ok","timestamp":1735594474529,"user_tz":300,"elapsed":14,"user":{"displayName":"Oliver Fritsche","userId":"15171898326940313848"}}},"outputs":[],"source":["# @title Loss Functions\n","import statistics\n","\n","class RMSELoss(nn.Module):\n","    def __init__(self):\n","        super(RMSELoss, self).__init__()\n","    def forward(self, output, target):\n","        loss = torch.sqrt(torch.mean((output - target) ** 2))\n","        return loss\n","\n","#prediction function\n","def RMSE_prediction(yhat_4,test_y, output_dim,print_losses=True):\n","\n","  s1=yhat_4.shape[0]*yhat_4.shape[1]\n","\n","  test_o=test_y.reshape((s1,output_dim))\n","  yhat=yhat_4.reshape((s1,output_dim))\n","\n","\n","\n","\n","  y_1_no=yhat[:,0]\n","  y_2_no=yhat[:,1]\n","  y_3_no=yhat[:,2]\n","\n","  y_1=y_1_no\n","  y_2=y_2_no\n","  y_3=y_3_no\n","\n","\n","  y_test_1=test_o[:,0]\n","  y_test_2=test_o[:,1]\n","  y_test_3=test_o[:,2]\n","\n","\n","\n","  cutoff=6\n","  fs=200\n","  order=4\n","\n","  nyq = 0.5 * fs\n","  ## filtering data ##\n","  def butter_lowpass_filter(data, cutoff, fs, order):\n","      normal_cutoff = cutoff / nyq\n","      # Get the filter coefficients\n","      b, a = butter(order, normal_cutoff, btype='low', analog=False)\n","      y = filtfilt(b, a, data)\n","      return y\n","\n","\n","\n","  Z_1=y_1\n","  Z_2=y_2\n","  Z_3=y_3\n","\n","\n","\n","  ###calculate RMSE\n","\n","  rmse_1 =((np.sqrt(mean_squared_error(y_test_1,y_1))))\n","  rmse_2 =((np.sqrt(mean_squared_error(y_test_2,y_2))))\n","  rmse_3 =((np.sqrt(mean_squared_error(y_test_3,y_3))))\n","\n","\n","\n","\n","\n","  p_1=np.corrcoef(y_1, y_test_1)[0, 1]\n","  p_2=np.corrcoef(y_2, y_test_2)[0, 1]\n","  p_3=np.corrcoef(y_3, y_test_3)[0, 1]\n","\n","\n","\n","\n","              ### Correlation ###\n","  p=np.array([p_1,p_2,p_3])\n","  #,p_4,p_5,p_6,p_7])\n","\n","\n","\n","\n","      #### Mean and standard deviation ####\n","\n","  rmse=np.array([rmse_1,rmse_2,rmse_3])\n","  #,rmse_4,rmse_5,rmse_6,rmse_7])\n","\n","      #### Mean and standard deviation ####\n","  m=statistics.mean(rmse)\n","  SD=statistics.stdev(rmse)\n","\n","\n","  m_c=statistics.mean(p)\n","  SD_c=statistics.stdev(p)\n","\n","\n","  if print_losses:\n","    print(rmse_1)\n","    print(rmse_2)\n","    print(rmse_3)\n","    print(\"\\n\")\n","    print(p_1)\n","    print(p_2)\n","    print(p_3)\n","    print('Mean: %.3f' % m,'+/- %.3f' %SD)\n","    print('Mean: %.3f' % m_c,'+/- %.3f' %SD_c)\n","\n","  return rmse, p, Z_1,Z_2,Z_3\n","  #,Z_4,Z_5,Z_6,Z_7"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"Yz_ioT_kTHzC","executionInfo":{"status":"ok","timestamp":1735594474529,"user_tz":300,"elapsed":13,"user":{"displayName":"Oliver Fritsche","userId":"15171898326940313848"}}},"outputs":[],"source":["\n","\n","\n","\n","\n","# @title Model Utils\n","\n","def reverse_diffusion(\n","    model,\n","    data_acc,   # [B, seq_len, feats_acc]\n","    data_gyr,   # [B, seq_len, feats_gyr]\n","    data_EMG,   # [B, seq_len, feats_emg]\n","    betas,      # beta_schedule_vals (1D tensor)\n","    num_steps,  # total diffusion steps\n","    device,\n","    batch_size, # data_acc.size(0)\n","    seq_len     # data_acc.size(1)\n","):\n","    \"\"\"\n","    Start from pure noise Y_T and iteratively denoise back to Y_0.\n","    Returns final Y_0 estimate of shape [B, seq_len].\n","    This uses the model(...) to predict noise at each step.\n","    \"\"\"\n","    model.eval()\n","\n","    # Y_T ~ N(0,I) shape [B, seq_len]\n","    # We expand it to [B, seq_len, 1] to match model's expected target shape\n","    Y_t = torch.randn(batch_size, seq_len, 1, device=device)\n","\n","    with torch.no_grad():\n","        for t in reversed(range(num_steps)):\n","            beta_t = betas[t]\n","            # 1) Build a timestep embedding: t / num_steps\n","            #    shape [B, seq_len, 1]\n","            time_embed = torch.full((batch_size, seq_len, 1), t/num_steps, device=device)\n","\n","            # 2) Predict noise using the model\n","            #    The model signature: model(acc, Y_noisy, time_embed) => predicted_noise\n","            predicted_noise = model(data_acc, data_gyr, data_EMG,time_embed)\n","\n","            # 3) Approximate Y_{t-1}\n","            #    If Y_t = sqrt(1-beta_t)*Y_{t-1} + sqrt(beta_t)*noise,\n","            #    => Y_{t-1} = (Y_t - sqrt(beta_t)*predicted_noise) / sqrt(1 - beta_t)\n","            Y_t_minus_1 = (Y_t - torch.sqrt(beta_t)*predicted_noise) / torch.sqrt(1 - beta_t)\n","\n","            # 4) Optionally add random noise if t > 0\n","            #    For purely deterministic sampling, omit this noise addition\n","            if t > 0:\n","                z = torch.randn_like(Y_t)\n","                Y_t_minus_1 += torch.sqrt(beta_t)*z\n","\n","            # Update\n","            Y_t = Y_t_minus_1\n","\n","    # Now Y_t is Y_0 => shape [B, seq_len, 1]. Convert to [B, seq_len].\n","    return Y_t.squeeze(-1)\n","\n","def evaluate_model(\n","    device,\n","    model,\n","    loader,\n","    criterion,            # Typically MSELoss or similar\n","    beta_schedule_vals,   # 1D tensor of betas\n","    num_steps\n","):\n","    \"\"\"\n","    During evaluation, we do reverse diffusion to get final Y_0,\n","    then measure RMSE/PCC between Y_0 and the true target Y.\n","    \"\"\"\n","    model.eval()\n","    total_loss = 0.0\n","    total_pcc = np.zeros(len(config.channels_joints))\n","    total_rmse = np.zeros(len(config.channels_joints))\n","\n","    with torch.no_grad():\n","        for (data_acc, data_gyr, target, data_EMG) in loader:\n","            # Move to device\n","            data_acc = data_acc.to(device).float()\n","            data_gyr = data_gyr.to(device).float()\n","            data_EMG = data_EMG.to(device).float()\n","            target   = target.to(device).float()  # [B, seq_len]\n","\n","            batch_size = data_acc.size(0)\n","            seq_len    = data_acc.size(1)\n","\n","            # ---------------------------\n","            # 1) Reverse diffusion\n","            # ---------------------------\n","            Y_hat = reverse_diffusion(\n","                model   = model,\n","                data_acc= data_acc,\n","                data_gyr= data_gyr,\n","                data_EMG= data_EMG,\n","                betas   = beta_schedule_vals,\n","                num_steps= num_steps,\n","                device  = device,\n","                batch_size= batch_size,\n","                seq_len= seq_len\n","            )\n","            # Y_hat shape: [B, seq_len]\n","\n","            # ---------------------------\n","            # 2) Compute MSE loss\n","            #    Now that we have a final guess for Y_0, we can do\n","            #    typical reconstruction metrics\n","            # ---------------------------\n","            # \"criterion\" is e.g. MSELoss, but it expects [B, seq_len, *] => might need unsqueeze\n","            # If your criterion is a standard MSELoss over 2D, just flatten the dims or do some reshape.\n","            # We'll do a simple approach: flatten both\n","            loss = criterion(Y_hat, target)\n","            total_loss += loss.item()\n","\n","            # ---------------------------\n","            # 3) Compute RMSE/PCC channel-wise\n","            #    If your target is shaped [B, seq_len, #channels], adjust accordingly.\n","            #    If each \"channel_joints\" is just 1 dimension of seq_len, adapt the slicing.\n","            # ---------------------------\n","            # We'll assume 'RMSE_prediction' is a function that can handle [B, seq_len] => [channels].\n","            # If your real data has multiple channels, you might have shape [B, seq_len, C].\n","            # For demonstration, let's assume we keep it at [B, seq_len] = 1 channel only, or we map it.\n","            batch_rmse, batch_pcc, _, _, _ = RMSE_prediction(\n","                Y_hat.detach().cpu().numpy(),\n","                target.detach().cpu().numpy(),\n","                len(config.channels_joints),\n","                print_losses=False\n","            )\n","            total_pcc += batch_pcc\n","            total_rmse += batch_rmse\n","\n","    avg_loss = total_loss / len(loader)\n","    avg_pcc  = total_pcc / len(loader)\n","    avg_rmse = total_rmse / len(loader)\n","    return avg_loss, avg_pcc, avg_rmse\n","\n","\n","def save_checkpoint(model, optimizer, epoch, filename, train_loss, val_loss, test_loss=None,\n","                    channelwise_metrics=None, history=None, curriculum_schedule=None):\n","\n","    checkpoint = {\n","        'epoch': epoch,\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","        'train_loss': train_loss,\n","        'val_loss': val_loss,\n","        'train_channelwise_metrics': channelwise_metrics['train'],\n","        'val_channelwise_metrics': channelwise_metrics['val'],\n","    }\n","\n","    if test_loss is not None:\n","        checkpoint['test_loss'] = test_loss\n","        checkpoint['test_channelwise_metrics'] = channelwise_metrics['test']\n","\n","    # Save the history (losses, PCCs, RMSEs, channel-wise metrics)\n","    if history:\n","        checkpoint['history'] = history\n","\n","    # Save curriculum schedule\n","    if curriculum_schedule:\n","        checkpoint['curriculum_schedule'] = curriculum_schedule\n","\n","    torch.save(checkpoint, filename)\n","    print(f\"Checkpoint saved for epoch {epoch + 1}\")\n","\n","\n","def beta_schedule(num_steps, start=1e-4, end=2e-2):\n","    \"\"\"\n","    Generates a linear beta schedule from `start` to `end`\n","    over `num_steps` diffusion steps.\n","    Returns: 1D tensor of shape (num_steps,)\n","    \"\"\"\n","    return torch.linspace(start, end, steps=num_steps)\n","\n","def train_teacher(device,\n","                  train_loader,\n","                  val_loader,\n","                  test_loader,\n","                  learn_rate,\n","                  epochs,\n","                  model,\n","                  filename,\n","                  loss_function,\n","                  optimizer=None,\n","                  l1_lambda=None,\n","                  train_from_last_epoch=False,\n","                  curriculum_loader=None,\n","                  beta_schedule_vals=beta_schedule(50, start=1e-4, end=2e-2),\n","                  num_steps=50):\n","    \"\"\"\n","    Train a diffusion-style model (noise prediction) but preserve\n","    the same function signature and basic structure. We'll accumulate\n","    MSE over timesteps for noise prediction during training.\n","    We'll then evaluate with the evaluate_model function above,\n","    which also measures noise-prediction MSE. If you want final\n","    signal metrics (RMSE/PCC), you must implement a reverse-diffusion\n","    pass in your evaluation.\n","\n","    Arguments:\n","      device: torch device\n","      train_loader, val_loader, test_loader: DataLoaders\n","      learn_rate: float learning rate\n","      epochs: number of epochs\n","      model: diffusion teacher model\n","      filename: checkpoint filename\n","      loss_function: typically nn.MSELoss\n","      optimizer: optional, if not provided we build an Adam\n","      l1_lambda: optional L1 regularization term\n","      train_from_last_epoch: whether to continue from last checkpoint\n","      curriculum_loader: optional curriculum logic\n","      beta_schedule_vals: 1D tensor for betas, must be provided for diffusion\n","      num_steps: total diffusion steps\n","    \"\"\"\n","    import time\n","    import os\n","    from tqdm import tqdm\n","\n","    if beta_schedule_vals is None:\n","        raise ValueError(\"beta_schedule_vals must be provided for diffusion training.\")\n","\n","    model.to(device)\n","    criterion = loss_function\n","\n","    if optimizer is None:\n","        optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n","\n","    train_losses = []\n","    val_losses = []\n","    test_losses = []\n","\n","    train_pccs = []\n","    val_pccs = []\n","    test_pccs = []\n","\n","    train_rmses = []\n","    val_rmses = []\n","    test_rmses = []\n","\n","    train_pccs_channelwise = []\n","    val_pccs_channelwise = []\n","    test_pccs_channelwise = []\n","\n","    train_rmses_channelwise = []\n","    val_rmses_channelwise = []\n","    test_rmses_channelwise = []\n","\n","    # Check for existing checkpoint\n","    last_epoch = 0\n","    checkpoint_path = f\"/content/MyDrive/MyDrive/models/{filename}/\"\n","    if train_from_last_epoch and os.path.exists(checkpoint_path):\n","        checkpoints = [f for f in os.listdir(checkpoint_path) if f.endswith('.pth')]\n","        if checkpoints:\n","            checkpoints.sort(key=lambda x: int(x.split('_')[-1].split('.')[0]))\n","            latest_checkpoint = checkpoints[-1]\n","            print(f\"Loading model from checkpoint: {latest_checkpoint}\")\n","            checkpoint = torch.load(os.path.join(checkpoint_path, latest_checkpoint))\n","            model.load_state_dict(checkpoint['model_state_dict'])\n","            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","            last_epoch = checkpoint['epoch']\n","\n","            # Load the history\n","            train_losses = checkpoint['history']['train_losses']\n","            val_losses = checkpoint['history']['val_losses']\n","            test_losses = checkpoint['history']['test_losses']\n","            train_pccs = checkpoint['history']['train_pccs']\n","            val_pccs = checkpoint['history']['val_pccs']\n","            test_pccs = checkpoint['history']['test_pccs']\n","            train_rmses = checkpoint['history']['train_rmses']\n","            val_rmses = checkpoint['history']['val_rmses']\n","            test_rmses = checkpoint['history']['test_rmses']\n","            train_pccs_channelwise = checkpoint['history']['train_pccs_channelwise']\n","            val_pccs_channelwise = checkpoint['history']['val_pccs_channelwise']\n","            test_pccs_channelwise = checkpoint['history']['test_pccs_channelwise']\n","            train_rmses_channelwise = checkpoint['history']['train_rmses_channelwise']\n","            val_rmses_channelwise = checkpoint['history']['val_rmses_channelwise']\n","            test_rmses_channelwise = checkpoint['history']['test_rmses_channelwise']\n","            if 'curriculum_schedule' in checkpoint:\n","                curriculum_loader.curriculum_schedule = checkpoint['curriculum_schedule']\n","        else:\n","            print(\"No checkpoints found, starting from scratch.\")\n","    else:\n","        print(\"Starting from scratch.\")\n","\n","    start_time = time.time()\n","    best_val_loss = float('inf')\n","    patience = 10\n","    patience_counter = 0\n","\n","    for epoch in range(last_epoch, epochs):\n","        epoch_start_time = time.time()\n","        model.train()\n","\n","        if curriculum_loader:\n","            curriculum_loader.update_epoch(epoch)\n","            train_loader, val_loader, test_loader = curriculum_loader.get_loaders()\n","\n","        # For channelwise metrics\n","        epoch_train_loss = np.zeros(len(config.channels_joints))\n","        epoch_train_pcc = np.zeros(len(config.channels_joints))\n","        epoch_train_rmse = np.zeros(len(config.channels_joints))\n","\n","        # ------------------------\n","        # TRAIN (Noise Prediction)\n","        # ------------------------\n","        for i, (data_acc, data_gyr, target, data_EMG) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs} Training\")):\n","            optimizer.zero_grad()\n","\n","            # Move inputs and targets to device\n","            data_acc = data_acc.to(device).float()  # [batch, seq_len, feat_dim]\n","            data_gyr = data_gyr.to(device).float()\n","            data_EMG = data_EMG.to(device).float()\n","            target = target.to(device).float()      # [batch, seq_len]\n","\n","            total_loss = 0.0\n","            for t in range(num_steps - 1, 0, -1):\n","                beta = beta_schedule_vals[t]\n","                noise = torch.randn_like(target)  # [batch, seq_len]\n","                y_noisy = torch.sqrt(1 - beta) * target + torch.sqrt(beta) * noise\n","                y_noisy_3d = y_noisy.unsqueeze(-1)  # Add last dim for compatibility: [batch, seq_len, 1]\n","\n","                # Timestep embedding, broadcasted across all modalities\n","                timestep = torch.full(\n","                    (data_acc.size(0), data_acc.size(1), 1),  # [batch, seq_len, 1]\n","                    t / num_steps,\n","                    device=device\n","                )\n","\n","                # Predict noise for all modalities\n","                noise_pred = model(data_acc, data_gyr, data_EMG, timestep)\n","\n","                # Loss computation\n","                step_loss = criterion(noise_pred, noise)\n","                total_loss += step_loss\n","\n","\n","            # L1 regularization if needed\n","            if l1_lambda is not None:\n","                l1_norm = sum(p.abs().sum() for p in model.parameters())\n","                total_loss += l1_lambda * l1_norm\n","\n","          # Backpropagation\n","            total_loss.backward()\n","            optimizer.step()\n","\n","            # For logging, we track the final 'total_loss' of the batch.\n","            # In standard diffusion, there's no direct final \"RMSE\" or \"PCC\" unless you do reconstruction.\n","            epoch_train_loss += total_loss.detach().cpu().numpy()\n","            # We keep placeholders for pcc and rmse\n","            epoch_train_pcc += 0.0\n","            epoch_train_rmse += 0.0\n","\n","        # Average train loss\n","        avg_train_loss = epoch_train_loss / len(train_loader)\n","        avg_train_pcc  = epoch_train_pcc  / len(train_loader)\n","        avg_train_rmse = epoch_train_rmse / len(train_loader)\n","\n","        train_losses.append(avg_train_loss)\n","        train_pccs.append(np.mean(avg_train_pcc))\n","        train_rmses.append(np.mean(avg_train_rmse))\n","\n","        train_pccs_channelwise.append(avg_train_pcc)\n","        train_rmses_channelwise.append(avg_train_rmse)\n","\n","        # ------------------------\n","        # VALIDATION\n","        # ------------------------\n","        avg_val_loss, avg_val_pcc, avg_val_rmse = evaluate_model(\n","            device,\n","            model,\n","            val_loader,\n","            criterion,\n","            beta_schedule_vals=beta_schedule_vals,  # pass to evaluate\n","            num_steps=num_steps\n","        )\n","        val_losses.append(avg_val_loss)\n","        val_pccs.append(np.mean(avg_val_pcc))\n","        val_rmses.append(np.mean(avg_val_rmse))\n","\n","        val_pccs_channelwise.append(avg_val_pcc)\n","        val_rmses_channelwise.append(avg_val_rmse)\n","\n","        # ------------------------\n","        # TEST\n","        # ------------------------\n","        avg_test_loss, avg_test_pcc, avg_test_rmse = evaluate_model(\n","            device,\n","            model,\n","            test_loader,\n","            criterion,\n","            beta_schedule_vals=beta_schedule_vals,  # pass to evaluate\n","            num_steps=num_steps\n","        )\n","        test_losses.append(avg_test_loss)\n","        test_pccs.append(np.mean(avg_test_pcc))\n","        test_rmses.append(np.mean(avg_test_rmse))\n","\n","        test_pccs_channelwise.append(avg_test_pcc)\n","        test_rmses_channelwise.append(avg_test_rmse)\n","\n","        print(f\"Epoch: {epoch + 1}, \"\n","              f\"Training Loss: {np.mean(avg_train_loss):.4f}, \"\n","              f\"Validation Loss: {np.mean(avg_val_loss):.4f}, \"\n","              f\"Test Loss: {np.mean(avg_test_loss):.4f}\")\n","        print(f\"Training RMSE: {np.mean(avg_train_rmse):.4f}, \"\n","              f\"Validation RMSE: {np.mean(avg_val_rmse):.4f}, \"\n","              f\"Test RMSE: {np.mean(avg_test_rmse):.4f}\")\n","        print(f\"Training PCC: {np.mean(avg_train_pcc):.4f}, \"\n","              f\"Validation PCC: {np.mean(avg_val_pcc):.4f}, \"\n","              f\"Test PCC: {np.mean(avg_test_pcc):.4f}\")\n","\n","        # Save checkpoint\n","        if not os.path.exists(checkpoint_path):\n","            os.makedirs(checkpoint_path)\n","\n","        history = {\n","            'train_losses': train_losses,\n","            'val_losses': val_losses,\n","            'test_losses': test_losses,\n","            'train_pccs': train_pccs,\n","            'val_pccs': val_pccs,\n","            'test_pccs': test_pccs,\n","            'train_rmses': train_rmses,\n","            'val_rmses': val_rmses,\n","            'test_rmses': test_rmses,\n","            'train_pccs_channelwise': train_pccs_channelwise,\n","            'val_pccs_channelwise': val_pccs_channelwise,\n","            'test_pccs_channelwise': test_pccs_channelwise,\n","            'train_rmses_channelwise': train_rmses_channelwise,\n","            'val_rmses_channelwise': val_rmses_channelwise,\n","            'test_rmses_channelwise': test_rmses_channelwise\n","        }\n","\n","        save_checkpoint(\n","            model,\n","            optimizer,\n","            epoch,\n","            f\"{checkpoint_path}/{filename}_epoch_{epoch + 1}.pth\",\n","            train_loss=avg_train_loss,\n","            val_loss=avg_val_loss,\n","            test_loss=avg_test_loss,\n","            channelwise_metrics={\n","                'train': {'pcc': avg_train_pcc, 'rmse': avg_train_rmse},\n","                'val':   {'pcc': avg_val_pcc,   'rmse': avg_val_rmse},\n","                'test':  {'pcc': avg_test_pcc,  'rmse': avg_test_rmse},\n","            },\n","            history=history,\n","            curriculum_schedule=curriculum_loader.curriculum_schedule if curriculum_loader else None\n","        )\n","\n","        # Early stopping\n","        if np.mean(avg_val_loss) < best_val_loss:\n","            best_val_loss = np.mean(avg_val_loss)\n","            torch.save(model.state_dict(), filename)\n","            patience_counter = 0\n","        else:\n","            patience_counter += 1\n","\n","        if patience_counter >= patience:\n","            print(f\"Stopping early after {epoch + 1} epochs\")\n","            break\n","\n","    end_time = time.time()\n","    print(f\"Total training time: {end_time - start_time:.2f} seconds\")\n","\n","    print(f\"loading best model from {filename}\")\n","    model.load_state_dict(torch.load(filename))\n","    model.eval()\n","\n","    return (model,\n","            train_losses, val_losses, test_losses,\n","            train_pccs, val_pccs, test_pccs,\n","            train_rmses, val_rmses, test_rmses)\n","\n","\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"9Eul1_WhMTqb","executionInfo":{"status":"ok","timestamp":1735594474529,"user_tz":300,"elapsed":11,"user":{"displayName":"Oliver Fritsche","userId":"15171898326940313848"}}},"outputs":[],"source":["# @title Helper Functions\n","\n","\n","# Function to create the teacher model with defaults from config\n","def create_teacher_model(input_acc, input_gyr, input_emg, base_weights_path=None, drop_prob=0.25, w=100):\n","    model = teacher(input_acc, input_gyr, input_emg, drop_prob=drop_prob, w=w)\n","\n","    if base_weights_path:\n","        # Load the initial weights from the base model\n","        model.load_state_dict(torch.load(base_weights_path))\n","\n","    return model\n","\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"hyj0qzUqXL93","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1735611681484,"user_tz":300,"elapsed":17206963,"user":{"displayName":"Oliver Fritsche","userId":"15171898326940313848"}},"outputId":"2f4b6cce-5cfd-475b-f2a3-55f9f9fffa42"},"outputs":[{"output_type":"stream","name":"stdout","text":["Running training with subject_1 as the test subject.\n","Model: TeacherModel_RMSELoss_test_subject_1_wl100_ol75_diffusion\n","Sharded data found at /content/datasets/dataset_wl100_ol75_train_2_3_4_5_6_7_8_9_10_11_12_13. Skipping resharding.\n","Sharded data found at /content/datasets/dataset_wl100_ol0_test_1. Skipping resharding.\n","Running model: TeacherModel_RMSELoss_test_subject_1_wl100_ol75_diffusion\n","Starting from scratch.\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1/10 Training: 100%|| 1305/1305 [27:19<00:00,  1.26s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Training Loss: 49.0024, Validation Loss: 53.8429, Test Loss: 54.1862\n","Training RMSE: 0.0000, Validation RMSE: 51.7754, Test RMSE: 47.7363\n","Training PCC: 0.0000, Validation PCC: -0.0001, Test PCC: 0.0009\n","Checkpoint saved for epoch 1\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/10 Training: 100%|| 1305/1305 [27:16<00:00,  1.25s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Training Loss: 49.0027, Validation Loss: 53.8567, Test Loss: 54.1983\n","Training RMSE: 0.0000, Validation RMSE: 51.7892, Test RMSE: 47.7513\n","Training PCC: 0.0000, Validation PCC: 0.0012, Test PCC: 0.0035\n","Checkpoint saved for epoch 2\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/10 Training: 100%|| 1305/1305 [27:21<00:00,  1.26s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 3, Training Loss: 48.9975, Validation Loss: 53.8453, Test Loss: 54.1791\n","Training RMSE: 0.0000, Validation RMSE: 51.7769, Test RMSE: 47.7297\n","Training PCC: 0.0000, Validation PCC: 0.0018, Test PCC: 0.0084\n","Checkpoint saved for epoch 3\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/10 Training: 100%|| 1305/1305 [27:18<00:00,  1.26s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 4, Training Loss: 48.9996, Validation Loss: 53.8468, Test Loss: 54.1879\n","Training RMSE: 0.0000, Validation RMSE: 51.7792, Test RMSE: 47.7382\n","Training PCC: 0.0000, Validation PCC: 0.0016, Test PCC: -0.0020\n","Checkpoint saved for epoch 4\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/10 Training: 100%|| 1305/1305 [27:27<00:00,  1.26s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 5, Training Loss: 48.9968, Validation Loss: 53.8514, Test Loss: 54.1967\n","Training RMSE: 0.0000, Validation RMSE: 51.7844, Test RMSE: 47.7456\n","Training PCC: 0.0000, Validation PCC: -0.0006, Test PCC: -0.0015\n","Checkpoint saved for epoch 5\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 6/10 Training: 100%|| 1305/1305 [27:38<00:00,  1.27s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 6, Training Loss: 48.9954, Validation Loss: 53.8484, Test Loss: 54.1967\n","Training RMSE: 0.0000, Validation RMSE: 51.7812, Test RMSE: 47.7428\n","Training PCC: 0.0000, Validation PCC: 0.0020, Test PCC: 0.0023\n","Checkpoint saved for epoch 6\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 7/10 Training: 100%|| 1305/1305 [27:34<00:00,  1.27s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 7, Training Loss: 48.9977, Validation Loss: 53.8536, Test Loss: 54.1879\n","Training RMSE: 0.0000, Validation RMSE: 51.7872, Test RMSE: 47.7415\n","Training PCC: 0.0000, Validation PCC: 0.0005, Test PCC: 0.0025\n","Checkpoint saved for epoch 7\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 8/10 Training: 100%|| 1305/1305 [27:44<00:00,  1.28s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 8, Training Loss: 48.9982, Validation Loss: 53.8537, Test Loss: 54.1886\n","Training RMSE: 0.0000, Validation RMSE: 51.7846, Test RMSE: 47.7404\n","Training PCC: 0.0000, Validation PCC: -0.0016, Test PCC: -0.0016\n","Checkpoint saved for epoch 8\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 9/10 Training: 100%|| 1305/1305 [27:36<00:00,  1.27s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 9, Training Loss: 48.9957, Validation Loss: 53.8509, Test Loss: 54.1858\n","Training RMSE: 0.0000, Validation RMSE: 51.7853, Test RMSE: 47.7395\n","Training PCC: 0.0000, Validation PCC: 0.0001, Test PCC: 0.0006\n","Checkpoint saved for epoch 9\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 10/10 Training: 100%|| 1305/1305 [27:37<00:00,  1.27s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 10, Training Loss: 49.0009, Validation Loss: 53.8562, Test Loss: 54.1914\n","Training RMSE: 0.0000, Validation RMSE: 51.7893, Test RMSE: 47.7403\n","Training PCC: 0.0000, Validation PCC: -0.0027, Test PCC: -0.0004\n","Checkpoint saved for epoch 10\n","Total training time: 17205.23 seconds\n","loading best model from TeacherModel_RMSELoss_test_subject_1_wl100_ol75_diffusion\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-7-db5fa62c4c7d>:459: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(filename))\n"]},{"output_type":"error","ename":"TypeError","evalue":"evaluate_model() missing 2 required positional arguments: 'beta_schedule_vals' and 'num_steps'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-0c831d34563d>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m      \u001b[0;31m#run model on test set and record result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_rmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test Loss: {test_loss:.4f}, Test PCC: {np.mean(test_pcc):.4f}, Test RMSE: {np.mean(test_rmse):.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mbest_rmse_per_subject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_rmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: evaluate_model() missing 2 required positional arguments: 'beta_schedule_vals' and 'num_steps'"]}],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import h5py\n","from tqdm.notebook import tqdm\n","import pandas as pd\n","import csv\n","\n","all_subjects= [f\"subject_{x}\" for x in range(1,14)]\n","input_acc, input_gyr, input_emg = 18,18,3\n","batch_size = 16\n","\n","# Placeholder for storing best RMSEs\n","best_rmse_per_subject = []\n","best_pcc_per_subject = []\n","\n","train_flag = True\n","\n","for test_subject in all_subjects:\n","\n","\n","\n","    print(f\"Running training with {test_subject} as the test subject.\")\n","\n","    # Set up the training subjects (all except the test subject)\n","    train_subjects = [subject for subject in all_subjects if subject != test_subject]\n","\n","    model_name = f'TeacherModel_RMSELoss_test_{test_subject}_wl{100}_ol{75}_diffusion'\n","    print(f\"Model: {model_name}\")\n","\n","    # Load the model configuration and data loaders\n","    model_config = {\n","        'model': create_teacher_model(input_acc, input_gyr, input_emg, w=100),\n","        'loss': RMSELoss(),\n","        'loaders': create_base_data_loaders(\n","            config=config,\n","            train_subjects=train_subjects,\n","            test_subjects=[test_subject],\n","            window_length=100,\n","            window_overlap=75,\n","            batch_size=batch_size\n","        ),\n","        'epochs': 10,\n","        'use_curriculum': False\n","    }\n","\n","    model = model_config['model']\n","    loss_function = model_config['loss']\n","    epochs = model_config.get(\"epochs\", 10)\n","    device = model_config.get(\"device\", torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n","    learn_rate = model_config.get(\"learn_rate\", 0.001)\n","    use_curriculum = model_config.get(\"use_curriculum\", False)\n","\n","    optimizer = model_config.get(\"optimizer\", None)\n","    l1_lambda = model_config.get(\"l1_lambda\", None)\n","\n","    print(f\"Running model: {model_name}\")\n","\n","    # Unpack the static loaders tuple (train_loader, val_loader, test_loader)\n","    train_loader, val_loader, test_loader = model_config['loaders']\n","    if train_flag:\n","    # Train the model and save only the best based on validation loss\n","      model, train_losses, val_losses, test_losses, train_pccs, val_pccs, test_pccs, train_rmses, val_rmses, test_rmses = train_teacher(\n","          device=device,\n","          train_loader=train_loader,\n","          val_loader=val_loader,\n","          test_loader=test_loader,\n","          learn_rate=learn_rate,\n","          epochs=epochs,\n","          model=model,\n","          filename=model_name,\n","          loss_function=loss_function,\n","          optimizer=optimizer,\n","          l1_lambda=l1_lambda,\n","          train_from_last_epoch=False\n","      )\n","    else:\n","      #load filename as model\n","      model.load_state_dict(torch.load(f\"{model_name}\"))\n","      model.to(device)\n","      model.eval()\n","\n","     #run model on test set and record result\n","    test_loss, test_pcc, test_rmse = evaluate_model(device, model, test_loader, loss_function)\n","    print(f\"Test Loss: {test_loss:.4f}, Test PCC: {np.mean(test_pcc):.4f}, Test RMSE: {np.mean(test_rmse):.4f}\")\n","    best_rmse_per_subject.append(np.mean(test_rmse))\n","    best_pcc_per_subject.append(np.mean(test_pcc))\n","\n","\n","# Compute the average of the best RMSEs across all subjects\n","\n"]},{"cell_type":"code","source":["\n","average_best_rmse = np.mean(best_rmse_per_subject)\n","average_best_pcc = np.mean(best_pcc_per_subject)\n","print(f\"Average of best RMSEs across all subjects: {average_best_rmse:.4f}\")\n","print(f\"Average of best PCCs across all subjects: {average_best_pcc:.4f}\")\n","print(best_rmse_per_subject)\n","print(best_pcc_per_subject)\n","\n","# subjects = [f'Subject {i+1}' for i in range(len(best_rmse_per_subject))]\n","\n","# print(best_rmse_per_subject)\n","# # Plot a bar chart with subject labels on the x-axis\n","# plt.figure(figsize=(10, 6))\n","# plt.bar(subjects, best_rmse_per_subject, color='blue', edgecolor='black')\n","# plt.title('Best RMSEs for Each Subject')\n","# plt.xlabel('Subjects')\n","# plt.ylabel('Best RMSE')\n","# plt.xticks(rotation=45, ha='right')\n","# plt.grid(True, axis='y')\n","# plt.tight_layout()\n","# plt.show()"],"metadata":{"id":"wzvnYVL7WXQd","executionInfo":{"status":"aborted","timestamp":1735611681487,"user_tz":300,"elapsed":71,"user":{"displayName":"Oliver Fritsche","userId":"15171898326940313848"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import zipfile\n","from datetime import datetime\n","\n","notebook_name = 'regression_benchmark_diffusion'\n","\n","# Create a timestamped folder name based on the notebook name\n","timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","folder_name = f\"{notebook_name}_checkpoints_{timestamp}\"\n","\n","# Make sure the folder exists\n","os.makedirs(folder_name, exist_ok=True)\n","\n","checkpoint_dir = '.'\n","\n","# Zip all checkpoint files and save in the new folder\n","zip_filename = f\"{folder_name}.zip\"\n","with zipfile.ZipFile(zip_filename, 'w') as zipf:\n","    # List files only in the current directory (no subfolders)\n","    for file in os.listdir(checkpoint_dir):\n","        if \"TeacherModel\" in str(file):\n","          file_path = os.path.join(checkpoint_dir, file)\n","          zipf.write(file_path, os.path.relpath(file_path, checkpoint_dir))\n","          print(f\"Checkpoint {file} has been added to the zip file.\")\n","print(f\"All checkpoints have been zipped and saved as {zip_filename}.\")\n","\n","\n"],"metadata":{"id":"SBkUF8_xH1AU","executionInfo":{"status":"aborted","timestamp":1735611681488,"user_tz":300,"elapsed":69,"user":{"displayName":"Oliver Fritsche","userId":"15171898326940313848"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Download the zip file to your local machine\n","from google.colab import files\n","files.download(zip_filename)"],"metadata":{"id":"hCDIXrKfxAij","executionInfo":{"status":"aborted","timestamp":1735611681488,"user_tz":300,"elapsed":67,"user":{"displayName":"Oliver Fritsche","userId":"15171898326940313848"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"dRTITfpAzvef","executionInfo":{"status":"aborted","timestamp":1735611681490,"user_tz":300,"elapsed":68,"user":{"displayName":"Oliver Fritsche","userId":"15171898326940313848"}}},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1OrqOEtMnWVFcSotx3oRVP7Kb6nAp5gKk","timestamp":1735587959636},{"file_id":"1ca6IWhaCNijsFxrjbz9MR7LAKEU5B2hT","timestamp":1729719161382},{"file_id":"1GG-T-9Pn3nWxXXDd3VzbjBUDDVBdquPe","timestamp":1727255073654},{"file_id":"1Odo2lxio-f6aVjKEBW4pGlFhEhRFuhig","timestamp":1726983228854},{"file_id":"1AKDQttSbC8SMdITVTIjya06gkxYOJ_NR","timestamp":1726706052358},{"file_id":"14JnySuUfKLfxc10Cw-McYCVHrbCl8e6x","timestamp":1726654334086},{"file_id":"1E6EBrFXKUIM8p9LD1XD4qYq-FnhvYnPz","timestamp":1726443626748},{"file_id":"1IYYQsxrg4uHErJuoV8MFIy_W67h0kWYl","timestamp":1726192532263},{"file_id":"11wbW9XhB8W7ViaUbAd6at_S5bG1-httV","timestamp":1726140420655},{"file_id":"12OM6Fm5sj9mUIEB3bktkaIeGsmM9Zqax","timestamp":1726107191041},{"file_id":"1Gu2Mego9pAJ1jH7ReLQef58Qo09Crmvu","timestamp":1725923231392},{"file_id":"1rdHb4TuCnnIDmoPaIx_xt1QlqeoqZ3aJ","timestamp":1725867609654},{"file_id":"1zVQFZK4F4nFC3rAsfc5f276kkLKyabA7","timestamp":1725770443175},{"file_id":"1_srYfBgGy8FQIMSohL9HL3Ac4ZZfvPVF","timestamp":1722559818032},{"file_id":"1ueeVtfayoqaNooAbjpcCBoKOWg7UmxAp","timestamp":1722359381849},{"file_id":"1ryl9H3tW6u9DyNInb-iS82rOZ4anjgZt","timestamp":1722295666388},{"file_id":"1lyKGsrpoLMhWE9Qz6A7qFZ5-o3fVuSVw","timestamp":1722291006477},{"file_id":"1JhajboXIAvcWgKNCN4Ljlg-Ebih6rbi3","timestamp":1722268029267},{"file_id":"1-tWEKDHgFp0R-NvBdAJIIFHZKc6185I4","timestamp":1722201240061},{"file_id":"1r91HidleatpLF4x2rdc9DnxWyb-U9exV","timestamp":1722197547794},{"file_id":"1sWKusmF7ocIZanW6vcld-Mr6bzERe-kb","timestamp":1722196228475},{"file_id":"1nzXq_89_RbuU-OR3LFr-idc_Gl8aypPt","timestamp":1722195060257},{"file_id":"1v8w64kwmH2zehSmEaUGsLZqJNEwecL-i","timestamp":1722185530003},{"file_id":"1QuAo2poyCHl3DFfE8Wrj9OnfDzv5HgpR","timestamp":1722181752384},{"file_id":"11qGVlcaE5KShLP8boMFZU_pIAYHJv2N1","timestamp":1722113928372},{"file_id":"1fzC0avZyr80RIwPOYEeAtJIlD_xB0-zv","timestamp":1722100536152}],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":0}