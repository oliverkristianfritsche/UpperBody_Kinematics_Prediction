{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3113,"status":"ok","timestamp":1729749722786,"user":{"displayName":"Oliver Fritsche","userId":"15171898326940313848"},"user_tz":240},"id":"YkI_GtjaTfqd","outputId":"08a99217-d00a-432c-9208-d1b491c1d1c0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/MyDrive; to attempt to forcibly remount, call drive.mount(\"/content/MyDrive\", force_remount=True).\n"]}],"source":["\n","#mount drive\n","from google.colab import drive\n","drive.mount('/content/MyDrive')\n","import seaborn as sns\n","sns.set_theme(\"paper\")\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ETk_LSRPvM--","executionInfo":{"status":"ok","timestamp":1729749725169,"user_tz":240,"elapsed":2389,"user":{"displayName":"Oliver Fritsche","userId":"15171898326940313848"}}},"outputs":[],"source":["# @title Initialize Config\n","\n","import torch\n","import numpy\n","class Config:\n","    def __init__(self, **kwargs):\n","        self.channels_imu_acc = kwargs.get('channels_imu_acc', [])\n","        self.channels_imu_gyr = kwargs.get('channels_imu_gyr', [])\n","        self.channels_joints = kwargs.get('channels_joints', [])\n","        self.channels_emg = kwargs.get('channels_emg', [])\n","        self.seed = kwargs.get('seed', 42)\n","        self.data_folder_name = kwargs.get('data_folder_name', 'default_data_folder_name')\n","        self.dataset_root = kwargs.get('dataset_root', 'default_dataset_root')\n","        self.imu_transforms = kwargs.get('imu_transforms', [])\n","        self.joint_transforms = kwargs.get('joint_transforms', [])\n","        self.emg_transforms = kwargs.get('emg_transforms', [])\n","        self.input_format = kwargs.get('input_format', 'csv')\n","\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","config = Config(\n","    data_folder_name='/content/MyDrive/MyDrive/sd_datacollection_v4/all_subjects_data_final.h5',\n","    dataset_root='/content/datasets',\n","    input_format=\"csv\",\n","    channels_imu_acc=['ACCX1', 'ACCY1', 'ACCZ1','ACCX2', 'ACCY2', 'ACCZ2', 'ACCX3', 'ACCY3', 'ACCZ3', 'ACCX4', 'ACCY4', 'ACCZ4', 'ACCX5', 'ACCY5', 'ACCZ5', 'ACCX6', 'ACCY6', 'ACCZ6'],\n","    channels_imu_gyr=['GYROX1', 'GYROY1', 'GYROZ1', 'GYROX2', 'GYROY2', 'GYROZ2', 'GYROX3', 'GYROY3', 'GYROZ3', 'GYROX4', 'GYROY4', 'GYROZ4', 'GYROX5', 'GYROY5', 'GYROZ5', 'GYROX6', 'GYROY6', 'GYROZ6'],\n","    channels_joints=['elbow_flex_r', 'arm_flex_r', 'arm_add_r'],\n","    channels_emg=['IM EMG4', 'IM EMG5', 'IM EMG6'],\n",")\n","\n","#set seeds\n","torch.manual_seed(config.seed)\n","numpy.random.seed(config.seed)\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"yvI4iVwAvg7y","executionInfo":{"status":"ok","timestamp":1729749725170,"user_tz":240,"elapsed":9,"user":{"displayName":"Oliver Fritsche","userId":"15171898326940313848"}}},"outputs":[],"source":["class DataSharder:\n","    def __init__(self, config, split):\n","        self.config = config\n","        self.h5_file_path = config.data_folder_name  # Path to the HDF5 file\n","        self.split = split\n","\n","    def load_data(self, subjects, window_length, window_overlap, dataset_name):\n","        print(f\"Processing subjects: {subjects} with window length: {window_length}, overlap: {window_overlap}\")\n","\n","        self.window_length = window_length\n","        self.window_overlap = window_overlap\n","\n","        # Process the data from the HDF5 file\n","        self._process_and_save_patients_h5(subjects, dataset_name)\n","\n","    def _process_and_save_patients_h5(self, subjects, dataset_name):\n","        # Open the HDF5 file\n","        with h5py.File(self.h5_file_path, 'r') as h5_file:\n","            dataset_folder = os.path.join(self.config.dataset_root, dataset_name, self.split).replace(\"subject\", \"\").replace(\"__\", \"_\")\n","            print(\"Dataset folder:\", dataset_folder)\n","\n","            if os.path.exists(dataset_folder):\n","                print(\"Dataset Exists, Skipping...\")\n","                return\n","\n","            os.makedirs(dataset_folder, exist_ok=True)\n","            print(\"Dataset folder created: \", dataset_folder)\n","\n","            for subject_id in tqdm(subjects, desc=\"Processing subjects\"):\n","                subject_key = subject_id\n","                if subject_key not in h5_file:\n","                    print(f\"Subject {subject_key} not found in the HDF5 file. Skipping.\")\n","                    continue\n","\n","                subject_data = h5_file[subject_key]\n","                session_keys = list(subject_data.keys())  # Sessions for this subject\n","\n","                for session_id in session_keys:\n","                    session_data_group = subject_data[session_id]\n","\n","                    for sessions_speed in session_data_group.keys():\n","                        session_data = session_data_group[sessions_speed]\n","\n","                        # Extract IMU, EMG, and Joint data as numpy arrays\n","                        imu_data, imu_columns = self._extract_channel_data(session_data, self.config.channels_imu_acc + self.config.channels_imu_gyr)\n","                        emg_data, emg_columns = self._extract_channel_data(session_data, self.config.channels_emg)\n","                        joint_data, joint_columns = self._extract_channel_data(session_data, self.config.channels_joints)\n","\n","                        # Shard the data into windows and save each window\n","                        self._save_windowed_data(imu_data, emg_data, joint_data, subject_key, session_id,sessions_speed, dataset_folder, imu_columns, emg_columns, joint_columns)\n","\n","    def _save_windowed_data(self, imu_data, emg_data, joint_data, subject_key, session_id, session_speed, dataset_folder, imu_columns, emg_columns, joint_columns):\n","        window_size = self.window_length\n","        overlap = self.window_overlap\n","        step_size = window_size - overlap\n","\n","        # Path to the CSV log file\n","        csv_file_path = os.path.join(dataset_folder, '..', f\"{self.split}_info.csv\")\n","\n","        # Ensure the folder exists\n","        os.makedirs(dataset_folder, exist_ok=True)\n","\n","        # Prepare CSV log headers (ensure the columns are 'file_name' and 'file_path')\n","        csv_headers = ['file_name', 'file_path']\n","\n","        # Create or append to the CSV log file\n","        file_exists = os.path.isfile(csv_file_path)\n","        with open(csv_file_path, mode='a', newline='') as csv_file:\n","            writer = csv.writer(csv_file)\n","\n","            # Write the headers only if the file is new\n","            if not file_exists:\n","                writer.writerow(csv_headers)\n","\n","            # Determine the total data length based on the minimum length across the data sources\n","            total_data_length = min(imu_data.shape[1], emg_data.shape[1], joint_data.shape[1])\n","\n","            # Adjust the starting point for windows based on total data length\n","            start = 2000 if total_data_length > 4000 else 0\n","\n","            # Ensure that each window across imu_data, emg_data, and joint_data has the same shape before concatenation\n","            for i in range(start, total_data_length - window_size + 1, step_size):\n","                imu_window = imu_data[:, i:i + window_size]\n","                emg_window = emg_data[:, i:i + window_size]\n","                joint_window = joint_data[:, i:i + window_size]\n","\n","                # Check if the window sizes are valid\n","                if imu_window.shape[1] == window_size and emg_window.shape[1] == window_size and joint_window.shape[1] == window_size:\n","                    # Convert windowed data to pandas DataFrame\n","\n","\n","\n","                    imu_df = pd.DataFrame(imu_window.T, columns=imu_columns)\n","                    emg_df = pd.DataFrame(emg_window.T, columns=emg_columns)\n","                    joint_df = pd.DataFrame(joint_window.T, columns=joint_columns)\n","\n","\n","\n","                    # Concatenate the data along the column axis\n","                    combined_df = pd.concat([imu_df, emg_df, joint_df], axis=1)\n","\n","                    # Save the combined windowed data as a CSV file\n","                    file_name = f\"{subject_key}_{session_id}_{session_speed}_win_{i}_ws{window_size}_ol{overlap}.csv\"\n","                    file_path = os.path.join(dataset_folder, file_name)\n","                    combined_df.to_csv(file_path, index=False)\n","\n","                    # Log the file name and path in the CSV (in the correct columns)\n","                    writer.writerow([file_name, file_path])\n","                else:\n","                    print(f\"Skipping window {i} due to mismatched window sizes.\")\n","\n","    def _extract_channel_data(self, session_data, channels):\n","      extracted_data = []\n","      new_column_names = []  # Initialize here\n","\n","      if isinstance(session_data, h5py.Dataset):\n","          if session_data.dtype.names:\n","              # Compound dataset\n","              column_names = session_data.dtype.names\n","              for channel in channels:\n","                  if channel in column_names:\n","                      channel_data = session_data[channel][:]\n","                      channel_data = pd.to_numeric(channel_data, errors='coerce')\n","                      df = pd.DataFrame(channel_data)\n","                      df_interpolated = df.interpolate(method='linear', axis=0, limit_direction='both')\n","                      extracted_data.append(df_interpolated.to_numpy().flatten())\n","                      new_column_names.append(channel)  # Populate here\n","                  else:\n","                      print(f\"Channel {channel} not found in compound dataset.\")\n","          else:\n","              # Simple dataset\n","              column_names = list(session_data.attrs.get('column_names', []))\n","              assert len(column_names) > 0, \"column_names not found in dataset attributes\"\n","              for channel in channels:\n","                  if channel in column_names:\n","                      col_idx = column_names.index(channel)\n","                      channel_data = session_data[:, col_idx]\n","                      channel_data = pd.to_numeric(channel_data, errors='coerce')\n","                      df = pd.DataFrame(channel_data)\n","                      df_interpolated = df.interpolate(method='linear', axis=0, limit_direction='both')\n","                      extracted_data.append(df_interpolated.to_numpy().flatten())\n","                      new_column_names.append(channel)\n","                  else:\n","                      print(f\"Channel {channel} not found in session data.\")\n","\n","      return np.array(extracted_data), new_column_names\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"uCr-VlFC8Nu7","executionInfo":{"status":"ok","timestamp":1729749725170,"user_tz":240,"elapsed":7,"user":{"displayName":"Oliver Fritsche","userId":"15171898326940313848"}}},"outputs":[],"source":["# @title Dataset creation\n","from torch.utils.data import Dataset, DataLoader\n","from torch.utils.data import random_split\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA\n","from torch.utils.data import ConcatDataset\n","import random\n","from torch.utils.data import TensorDataset\n","\n","class ImuJointPairDataset(Dataset):\n","    def __init__(self, config, subjects, window_length, window_overlap, split='train', dataset_train_name='train', dataset_test_name='test'):\n","        self.config = config\n","        self.split = split\n","        self.subjects = subjects\n","        self.window_length = window_length\n","        self.window_overlap = window_overlap if split == 'train' else 0\n","        self.input_format = config.input_format\n","        self.channels_imu_acc = config.channels_imu_acc\n","        self.channels_imu_gyr = config.channels_imu_gyr\n","        self.channels_joints = config.channels_joints\n","        self.channels_emg = config.channels_emg\n","\n","        # Convert the list of subjects to a string that is path-safe\n","        subjects_str = \"_\".join(map(str, subjects)).replace('subject', '').replace('__', '_')\n","\n","        # Use dataset_train_name or dataset_test_name based on split\n","        if split == 'train':\n","            dataset_name = f\"dataset_wl{self.window_length}_ol{self.window_overlap}_train{subjects_str}\"\n","        else:\n","            dataset_name = f\"dataset_wl{self.window_length}_ol{self.window_overlap}_test{subjects_str}\"\n","\n","        self.dataset_name = dataset_name\n","\n","        # Define the root directory based on dataset name\n","        self.root_dir = os.path.join(self.config.dataset_root, self.dataset_name)\n","\n","        # Ensure sharded data exists, if not, reshard\n","        self.ensure_resharded(subjects, dataset_train_name if split == 'train' else dataset_test_name)\n","\n","        info_path = os.path.join(self.root_dir, f\"{split}_info.csv\")\n","        self.data = pd.read_csv(info_path)\n","\n","    def ensure_resharded(self, subjects, dataset_name):\n","        if not os.path.exists(self.root_dir):\n","            print(f\"Sharded data not found at {self.root_dir}. Resharding...\")\n","            data_sharder = DataSharder(self.config,self.split)\n","            # Pass dynamic parameters to sharder\n","            data_sharder.load_data(subjects, window_length=self.window_length, window_overlap=self.window_overlap, dataset_name=self.dataset_name)\n","        else:\n","            print(f\"Sharded data found at {self.root_dir}. Skipping resharding.\")\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        file_path = os.path.join(self.root_dir,self.split, self.data.iloc[idx, 0])\n","\n","        if self.input_format == \"csv\":\n","            combined_data = pd.read_csv(file_path)\n","        else:\n","            raise ValueError(\"Unsupported input format: {}\".format(self.input_format))\n","\n","        imu_data_acc, imu_data_gyr, joint_data, emg_data = self._extract_and_transform(combined_data)\n","        return imu_data_acc, imu_data_gyr, joint_data, emg_data\n","\n","    def _extract_and_transform(self, combined_data):\n","        imu_data_acc = self._extract_channels(combined_data, self.channels_imu_acc)\n","        imu_data_gyr = self._extract_channels(combined_data, self.channels_imu_gyr)\n","        joint_data = self._extract_channels(combined_data, self.channels_joints)\n","        emg_data = self._extract_channels(combined_data, self.channels_emg)\n","\n","        imu_data_acc = self.apply_transforms(imu_data_acc, self.config.imu_transforms)\n","        imu_data_gyr = self.apply_transforms(imu_data_gyr, self.config.imu_transforms)\n","        joint_data = self.apply_transforms(joint_data, self.config.joint_transforms)\n","        emg_data = self.apply_transforms(emg_data, self.config.emg_transforms)\n","\n","        return imu_data_acc, imu_data_gyr, joint_data, emg_data\n","\n","    def _extract_channels(self, combined_data, channels):\n","        return combined_data[channels].values if self.input_format == \"csv\" else combined_data[:, channels]\n","\n","    def apply_transforms(self, data, transforms):\n","        for transform in transforms:\n","            data = transform(data)\n","        return torch.tensor(data, dtype=torch.float32)\n","\n","def create_base_data_loaders(\n","    config,\n","    train_subjects,\n","    test_subjects,\n","    window_length=100,\n","    window_overlap=75,\n","    batch_size=64,\n","    dataset_train_name='train',\n","    dataset_test_name='test'\n","):\n","    # Create datasets with explicit parameters\n","    train_dataset = ImuJointPairDataset(\n","        config=config,\n","        subjects=train_subjects,\n","        window_length=window_length,\n","        window_overlap=window_overlap,\n","        split='train',\n","        dataset_train_name=dataset_train_name\n","    )\n","\n","    test_dataset = ImuJointPairDataset(\n","        config=config,\n","        subjects=test_subjects,\n","        window_length=window_length,\n","        window_overlap=window_overlap,\n","        split='test',\n","        dataset_test_name=dataset_test_name\n","    )\n","\n","    # Split train dataset into training and validation sets\n","    train_size = int(0.9 * len(train_dataset))\n","    val_size = len(train_dataset) - train_size\n","    train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n","\n","    # Create data loaders\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","    return train_loader, val_loader, test_loader\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"oAsMzR7bSB5J","executionInfo":{"status":"ok","timestamp":1729749725567,"user_tz":240,"elapsed":403,"user":{"displayName":"Oliver Fritsche","userId":"15171898326940313848"}}},"outputs":[],"source":["# @title Kinematicsnet Architecture\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import time\n","from scipy.signal import butter, filtfilt\n","from sklearn.metrics import mean_squared_error\n","import numpy as np\n","class Encoder_1(nn.Module):\n","    def __init__(self, input_dim, dropout):\n","        super(Encoder_1, self).__init__()\n","        self.lstm_1 = nn.LSTM(input_dim, 128, bidirectional=True, batch_first=True, dropout=0)\n","        self.lstm_2 = nn.LSTM(256, 64, bidirectional=True, batch_first=True, dropout=0)\n","        self.flatten = nn.Flatten()\n","        self.fc = nn.Linear(128, 32)\n","        self.dropout_1 = nn.Dropout(dropout)\n","        self.dropout_2 = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        out_1, (h_1, _) = self.lstm_1(x)\n","        out_1 = self.dropout_1(out_1)\n","        out_2, (h_2, _) = self.lstm_2(out_1)\n","        out_2 = self.dropout_2(out_2)\n","        return out_2, (h_1, h_2)\n","\n","class Encoder_2(nn.Module):\n","    def __init__(self, input_dim, dropout):\n","        super(Encoder_2, self).__init__()\n","        self.gru_1 = nn.GRU(input_dim, 128, bidirectional=True, batch_first=True, dropout=0)\n","        self.gru_2 = nn.GRU(256, 64, bidirectional=True, batch_first=True, dropout=0)\n","        self.flatten = nn.Flatten()\n","        self.fc = nn.Linear(128, 32)\n","        self.dropout_1 = nn.Dropout(dropout)\n","        self.dropout_2 = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        out_1, h_1 = self.gru_1(x)\n","        out_1 = self.dropout_1(out_1)\n","        out_2, h_2 = self.gru_2(out_1)\n","        out_2 = self.dropout_2(out_2)\n","        return out_2, (h_1, h_2)\n","\n","\n","class GatingModule(nn.Module):\n","    def __init__(self, input_size):\n","        super(GatingModule, self).__init__()\n","        self.gate = nn.Sequential(\n","            nn.Linear(2*input_size, input_size),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, input1, input2):\n","        # Apply gating mechanism\n","        gate_output = self.gate(torch.cat((input1,input2),dim=-1))\n","\n","        # Scale the inputs based on the gate output\n","        gated_input1 = input1 * gate_output\n","        gated_input2 = input2 * (1 - gate_output)\n","\n","        # Combine the gated inputs\n","        output = gated_input1 + gated_input2\n","        return output\n","#variable w needs to be checked for correct value, stand-in value used\n","class teacher(nn.Module):\n","    def __init__(self, input_acc, input_gyr, input_emg, drop_prob=0.25, w=100):\n","        super(teacher, self).__init__()\n","\n","        self.w=w\n","        self.encoder_1_acc=Encoder_1(input_acc, drop_prob)\n","        self.encoder_1_gyr=Encoder_1(input_gyr, drop_prob)\n","        self.encoder_1_emg=Encoder_1(input_emg, drop_prob)\n","\n","        self.encoder_2_acc=Encoder_2(input_acc, drop_prob)\n","        self.encoder_2_gyr=Encoder_2(input_gyr, drop_prob)\n","        self.encoder_2_emg=Encoder_2(input_emg, drop_prob)\n","\n","        self.BN_acc= nn.BatchNorm1d(input_acc, affine=False)\n","        self.BN_gyr= nn.BatchNorm1d(input_gyr, affine=False)\n","        self.BN_emg= nn.BatchNorm1d(input_emg, affine=False)\n","\n","\n","        self.fc = nn.Linear(2*3*128+128,3)\n","        self.dropout=nn.Dropout(p=.05)\n","\n","        self.gate_1=GatingModule(128)\n","        self.gate_2=GatingModule(128)\n","        self.gate_3=GatingModule(128)\n","\n","        self.fc_kd = nn.Linear(3*128, 2*128)\n","\n","               # Define the gating network\n","        self.weighted_feat = nn.Sequential(\n","            nn.Linear(128, 1),\n","            nn.Sigmoid())\n","\n","        self.attention=nn.MultiheadAttention(3*128,4,batch_first=True)\n","        self.gating_net = nn.Sequential(nn.Linear(128*3, 3*128), nn.Sigmoid())\n","        self.gating_net_1 = nn.Sequential(nn.Linear(2*3*128+128, 2*3*128+128), nn.Sigmoid())\n","\n","        self.pool = nn.MaxPool1d(kernel_size=2)\n","\n","\n","    def forward(self, x_acc, x_gyr, x_emg):\n","\n","        x_acc_1=x_acc.view(x_acc.size(0)*x_acc.size(1),x_acc.size(-1))\n","        x_gyr_1=x_gyr.view(x_gyr.size(0)*x_gyr.size(1),x_gyr.size(-1))\n","        x_emg_1=x_emg.view(x_emg.size(0)*x_emg.size(1),x_emg.size(-1))\n","\n","        x_acc_1=self.BN_acc(x_acc_1)\n","        x_gyr_1=self.BN_gyr(x_gyr_1)\n","        x_emg_1=self.BN_emg(x_emg_1)\n","\n","        x_acc_2=x_acc_1.view(-1, self.w, x_acc_1.size(-1))\n","        x_gyr_2=x_gyr_1.view(-1, self.w, x_gyr_1.size(-1))\n","        x_emg_2=x_emg_1.view(-1, self.w, x_emg_1.size(-1))\n","\n","        # Pass through Encoder 1 for each modality and capture hidden states\n","        x_acc_1, (h_acc_1, _) = self.encoder_1_acc(x_acc_2)\n","        x_gyr_1, (h_gyr_1, _) = self.encoder_1_gyr(x_gyr_2)\n","        x_emg_1, (h_emg_1, _) = self.encoder_1_emg(x_emg_2)\n","\n","        # Pass through Encoder 2 for each modality and capture hidden states\n","        x_acc_2, (h_acc_2, _) = self.encoder_2_acc(x_acc_2)\n","        x_gyr_2, (h_gyr_2, _) = self.encoder_2_gyr(x_gyr_2)\n","        x_emg_2, (h_emg_2, _) = self.encoder_2_emg(x_emg_2)\n","\n","        # x_acc=torch.cat((x_acc_1,x_acc_2),dim=-1)\n","        # x_gyr=torch.cat((x_gyr_1,x_gyr_2),dim=-1)\n","        # x_emg=torch.cat((x_emg_1,x_emg_2),dim=-1)\n","\n","        x_acc=self.gate_1(x_acc_1,x_acc_2)\n","        x_gyr=self.gate_2(x_gyr_1,x_gyr_2)\n","        x_emg=self.gate_3(x_emg_1,x_emg_2)\n","\n","        x=torch.cat((x_acc,x_gyr,x_emg),dim=-1)\n","        x_kd=self.fc_kd(x)\n","\n","\n","        out_1, attn_output_weights=self.attention(x,x,x)\n","\n","        gating_weights = self.gating_net(x)\n","        out_2=gating_weights*x\n","\n","        weights_1 = self.weighted_feat(x[:,:,0:128])\n","        weights_2 = self.weighted_feat(x[:,:,128:2*128])\n","        weights_3 = self.weighted_feat(x[:,:,2*128:3*128])\n","        x_1=weights_1*x[:,:,0:128]\n","        x_2=weights_2*x[:,:,128:2*128]\n","        x_3=weights_3*x[:,:,2*128:3*128]\n","        out_3=x_1+x_2+x_3\n","\n","        out=torch.cat((out_1,out_2,out_3),dim=-1)\n","\n","        gating_weights_1 = self.gating_net_1(out)\n","        out=gating_weights_1*out\n","\n","        out=self.fc(out)\n","\n","        #print(out.shape)\n","        return out, x_kd, (h_acc_1, h_acc_2, h_gyr_1, h_gyr_2, h_emg_1, h_emg_2)\n","\n","\n","class TeacherAutoencoder(nn.Module):\n","    def __init__(self, input_acc, input_gyr, input_emg, drop_prob=0.25, w=100):\n","        super(TeacherAutoencoder, self).__init__()\n","\n","        self.w = w\n","\n","        # Encoder (same as original)\n","        self.encoder_1_acc = Encoder_1(input_acc, drop_prob)\n","        self.encoder_1_gyr = Encoder_1(input_gyr, drop_prob)\n","        self.encoder_1_emg = Encoder_1(input_emg, drop_prob)\n","\n","        self.encoder_2_acc = Encoder_2(input_acc, drop_prob)\n","        self.encoder_2_gyr = Encoder_2(input_gyr, drop_prob)\n","        self.encoder_2_emg = Encoder_2(input_emg, drop_prob)\n","\n","        self.BN_acc = nn.BatchNorm1d(input_acc, affine=False)\n","        self.BN_gyr = nn.BatchNorm1d(input_gyr, affine=False)\n","        self.BN_emg = nn.BatchNorm1d(input_emg, affine=False)\n","\n","        # Fully connected layer for joint angle prediction\n","        self.fc = nn.Linear(2 * 3 * 128 + 128, 3)\n","        self.dropout = nn.Dropout(p=.05)\n","\n","        self.gate_1 = GatingModule(128)\n","        self.gate_2 = GatingModule(128)\n","        self.gate_3 = GatingModule(128)\n","\n","        # Gating and attention mechanisms\n","        self.weighted_feat = nn.Sequential(nn.Linear(128, 1), nn.Sigmoid())\n","        self.attention = nn.MultiheadAttention(3 * 128, 4, batch_first=True)\n","        self.gating_net = nn.Sequential(nn.Linear(128 * 3, 3 * 128), nn.Sigmoid())\n","        self.gating_net_1 = nn.Sequential(nn.Linear(2 * 3 * 128 + 128, 2 * 3 * 128 + 128), nn.Sigmoid())\n","\n","        # Max pooling for reconstruction mode\n","        self.pool = nn.MaxPool1d(kernel_size=2)\n","\n","        # Adjusted Decoder to ensure matching shapes\n","        self.decoder_fc = nn.Linear(3 * 128, 3 * 128)\n","\n","        self.decoder_2_acc = Encoder_2(128, drop_prob)\n","        self.decoder_2_gyr = Encoder_2(128, drop_prob)\n","        self.decoder_2_emg = Encoder_2(128, drop_prob)\n","\n","        self.decoder_1_acc = Encoder_1(128, drop_prob)\n","        self.decoder_1_gyr = Encoder_1(128, drop_prob)\n","        self.decoder_1_emg = Encoder_1(128, drop_prob)\n","\n","        # Final layer to map 128 features back to original input size\n","        self.final_fc_acc = nn.Linear(128, input_acc)\n","        self.final_fc_gyr = nn.Linear(128, input_gyr)\n","        self.final_fc_emg = nn.Linear(128, input_emg)\n","\n","    def forward(self, x_acc, x_gyr, x_emg, predict_mode=True):\n","      # Reshape inputs to (batch_size * window_size, features) for batch normalization\n","      x_acc_1 = x_acc.view(-1, x_acc.size(-1))\n","      x_gyr_1 = x_gyr.view(-1, x_gyr.size(-1))\n","      x_emg_1 = x_emg.view(-1, x_emg.size(-1))\n","\n","      # Apply batch normalization across the features\n","      x_acc_1 = self.BN_acc(x_acc_1)\n","      x_gyr_1 = self.BN_gyr(x_gyr_1)\n","      x_emg_1 = self.BN_emg(x_emg_1)\n","\n","      # Reshape back to (batch_size, time_steps, features)\n","      x_acc_1 = x_acc_1.view(x_acc.size(0), x_acc.size(1), -1)\n","      x_gyr_1 = x_gyr_1.view(x_gyr.size(0), x_gyr.size(1), -1)\n","      x_emg_1 = x_emg_1.view(x_emg.size(0), x_emg.size(1), -1)\n","\n","      x_acc_2 = x_acc_1.view(-1, self.w, x_acc_1.size(-1))  # Reshape back\n","      x_gyr_2 = x_gyr_1.view(-1, self.w, x_gyr_1.size(-1))\n","      x_emg_2 = x_emg_1.view(-1, self.w, x_emg_1.size(-1))\n","\n","      # Encoder forward pass\n","      x_acc_1, (h_acc_1, _) = self.encoder_1_acc(x_acc_2)\n","      x_gyr_1, (h_gyr_1, _) = self.encoder_1_gyr(x_gyr_2)\n","      x_emg_1, (h_emg_1, _) = self.encoder_1_emg(x_emg_2)\n","\n","      x_acc_2, (h_acc_2, _) = self.encoder_2_acc(x_acc_2)\n","      x_gyr_2, (h_gyr_2, _) = self.encoder_2_gyr(x_gyr_2)\n","      x_emg_2, (h_emg_2, _) = self.encoder_2_emg(x_emg_2)\n","\n","      x_acc = self.gate_1(x_acc_1, x_acc_2)\n","      x_gyr = self.gate_2(x_gyr_1, x_gyr_2)\n","      x_emg = self.gate_3(x_emg_1, x_emg_2)\n","\n","      x = torch.cat((x_acc, x_gyr, x_emg), dim=-1)\n","\n","      if predict_mode:\n","          # --- Prediction mode ---\n","          out_1, attn_output_weights = self.attention(x, x, x)\n","\n","          gating_weights = self.gating_net(x)\n","          out_2 = gating_weights * x\n","\n","          weights_1 = self.weighted_feat(x[:, :, 0:128])\n","          weights_2 = self.weighted_feat(x[:, :, 128:2 * 128])\n","          weights_3 = self.weighted_feat(x[:, :, 2 * 128:3 * 128])\n","          x_1 = weights_1 * x[:, :, 0:128]\n","          x_2 = weights_2 * x[:, :, 128:2 * 128]\n","          x_3 = weights_3 * x[:, :, 2 * 128:3 * 128]\n","          out_3 = x_1 + x_2 + x_3\n","\n","          out = torch.cat((out_1, out_2, out_3), dim=-1)\n","\n","          gating_weights_1 = self.gating_net_1(out)\n","          out = gating_weights_1 * out\n","\n","          out = self.fc(out)\n","          return out, (h_acc_1, h_acc_2, h_gyr_1, h_gyr_2, h_emg_1, h_emg_2)\n","\n","      else:\n","        # --- Reconstruction mode ---\n","\n","        # Directly use the features (x_acc, x_gyr, x_emg) instead of x_kd for reconstruction\n","\n","        # Concatenate the features for decoding\n","        x_decoded = torch.cat((x_acc, x_gyr, x_emg), dim=-1)\n","\n","        # Pass through decoder_fc to reduce dimensions back\n","        x_decoded = self.decoder_fc(x_decoded)\n","\n","        # Ensure the decoded size is correct\n","        if x_decoded.size(-1) != 128 * 3:\n","            raise RuntimeError(f\"Expected input size of {128 * 3}, but got {x_decoded.size(-1)}\")\n","\n","        x_acc_dec = x_decoded[:, :, :128]\n","        x_gyr_dec = x_decoded[:, :, 128:2 * 128]\n","        x_emg_dec = x_decoded[:, :, 2 * 128:3 * 128]\n","\n","        # Decoder expects input of size 128\n","        x_acc_dec, _ = self.decoder_2_acc(x_acc_dec)\n","        x_gyr_dec, _ = self.decoder_2_gyr(x_gyr_dec)\n","        x_emg_dec, _ = self.decoder_2_emg(x_emg_dec)\n","\n","        x_acc_dec, _ = self.decoder_1_acc(x_acc_dec)\n","        x_gyr_dec, _ = self.decoder_1_gyr(x_gyr_dec)\n","        x_emg_dec, _ = self.decoder_1_emg(x_emg_dec)\n","\n","        # Map the decoded features back to the original input size (18)\n","        x_acc_dec = self.final_fc_acc(x_acc_dec)\n","        x_gyr_dec = self.final_fc_gyr(x_gyr_dec)\n","        x_emg_dec = self.final_fc_emg(x_emg_dec)\n","\n","        return x_acc_dec, x_gyr_dec, x_emg_dec\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"wmdCuEysPimX","executionInfo":{"status":"ok","timestamp":1729749725568,"user_tz":240,"elapsed":22,"user":{"displayName":"Oliver Fritsche","userId":"15171898326940313848"}}},"outputs":[],"source":["# @title Loss Functions\n","import statistics\n","\n","def reconstruction_loss(output, target):\n","    # Output is (x_acc_dec, x_gyr_dec, x_emg_dec), and target is (x_acc, x_gyr, x_emg)\n","    loss_acc = RMSELoss()(output[0], target[0])\n","    loss_gyr = RMSELoss()(output[1], target[1])\n","    loss_emg = RMSELoss()(output[2], target[2])\n","    return loss_acc + loss_gyr + loss_emg\n","\n","class RMSELoss(nn.Module):\n","    def __init__(self):\n","        super(RMSELoss, self).__init__()\n","    def forward(self, output, target):\n","        loss = torch.sqrt(torch.mean((output - target) ** 2))\n","        return loss\n","\n","def reconstruction_loss(output, target):\n","    # Output is (x_acc_dec, x_gyr_dec, x_emg_dec), and target is (x_acc, x_gyr, x_emg)\n","    loss_acc = RMSELoss()(output[0], target[0])\n","    loss_gyr = RMSELoss()(output[1], target[1])\n","    loss_emg = RMSELoss()(output[2], target[2])\n","    return loss_acc + loss_gyr + loss_emg\n","\n","#prediction function\n","def RMSE_prediction(yhat_4,test_y, output_dim,print_losses=True):\n","\n","  s1=yhat_4.shape[0]*yhat_4.shape[1]\n","\n","  test_o=test_y.reshape((s1,output_dim))\n","  yhat=yhat_4.reshape((s1,output_dim))\n","\n","\n","\n","\n","  y_1_no=yhat[:,0]\n","  y_2_no=yhat[:,1]\n","  y_3_no=yhat[:,2]\n","\n","  y_1=y_1_no\n","  y_2=y_2_no\n","  y_3=y_3_no\n","\n","\n","  y_test_1=test_o[:,0]\n","  y_test_2=test_o[:,1]\n","  y_test_3=test_o[:,2]\n","\n","\n","\n","  cutoff=6\n","  fs=200\n","  order=4\n","\n","  nyq = 0.5 * fs\n","  ## filtering data ##\n","  def butter_lowpass_filter(data, cutoff, fs, order):\n","      normal_cutoff = cutoff / nyq\n","      # Get the filter coefficients\n","      b, a = butter(order, normal_cutoff, btype='low', analog=False)\n","      y = filtfilt(b, a, data)\n","      return y\n","\n","\n","\n","  Z_1=y_1\n","  Z_2=y_2\n","  Z_3=y_3\n","\n","\n","\n","  ###calculate RMSE\n","\n","  rmse_1 =((np.sqrt(mean_squared_error(y_test_1,y_1))))\n","  rmse_2 =((np.sqrt(mean_squared_error(y_test_2,y_2))))\n","  rmse_3 =((np.sqrt(mean_squared_error(y_test_3,y_3))))\n","\n","\n","\n","\n","\n","  p_1=np.corrcoef(y_1, y_test_1)[0, 1]\n","  p_2=np.corrcoef(y_2, y_test_2)[0, 1]\n","  p_3=np.corrcoef(y_3, y_test_3)[0, 1]\n","\n","\n","\n","\n","              ### Correlation ###\n","  p=np.array([p_1,p_2,p_3])\n","  #,p_4,p_5,p_6,p_7])\n","\n","\n","\n","\n","      #### Mean and standard deviation ####\n","\n","  rmse=np.array([rmse_1,rmse_2,rmse_3])\n","  #,rmse_4,rmse_5,rmse_6,rmse_7])\n","\n","      #### Mean and standard deviation ####\n","  m=statistics.mean(rmse)\n","  SD=statistics.stdev(rmse)\n","\n","\n","  m_c=statistics.mean(p)\n","  SD_c=statistics.stdev(p)\n","\n","\n","  if print_losses:\n","    print(rmse_1)\n","    print(rmse_2)\n","    print(rmse_3)\n","    print(\"\\n\")\n","    print(p_1)\n","    print(p_2)\n","    print(p_3)\n","    print('Mean: %.3f' % m,'+/- %.3f' %SD)\n","    print('Mean: %.3f' % m_c,'+/- %.3f' %SD_c)\n","\n","  return rmse, p, Z_1,Z_2,Z_3\n","  #,Z_4,Z_5,Z_6,Z_7"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"Yz_ioT_kTHzC","executionInfo":{"status":"ok","timestamp":1729749725570,"user_tz":240,"elapsed":22,"user":{"displayName":"Oliver Fritsche","userId":"15171898326940313848"}}},"outputs":[],"source":["\n","\n","\n","\n","\n","# @title Model Utils\n","\n","\n","# Evaluation function\n","def evaluate_model(device, model, loader, criterion):\n","    \"\"\"Runs evaluation on the validation or test set.\"\"\"\n","    model.eval()\n","    total_loss = 0.0\n","    total_pcc = np.zeros(len(config.channels_joints))\n","    total_rmse = np.zeros(len(config.channels_joints))\n","\n","    with torch.no_grad():\n","        for i, (data_acc, data_gyr, target, data_EMG) in enumerate(loader):\n","            output= model(data_acc.to(device).float(), data_gyr.to(device).float(), data_EMG.to(device).float())[0]\n","\n","\n","            loss = criterion(output, target.to(device).float())\n","\n","            batch_rmse, batch_pcc, _, _, _ = RMSE_prediction(output.detach().cpu().numpy(), target.detach().cpu().numpy(), len(config.channels_joints), print_losses=False)\n","            total_loss += loss.item()\n","            total_pcc += batch_pcc\n","            total_rmse += batch_rmse\n","\n","    avg_loss = total_loss / len(loader)\n","    avg_pcc = total_pcc / len(loader)\n","    avg_rmse = total_rmse / len(loader)\n","\n","    return avg_loss, avg_pcc, avg_rmse\n","\n","\n","\n","def save_checkpoint(model, optimizer, epoch, filename, train_loss, val_loss, test_loss=None,\n","                    channelwise_metrics=None, history=None, curriculum_schedule=None):\n","\n","    checkpoint = {\n","        'epoch': epoch,\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","        'train_loss': train_loss,\n","        'val_loss': val_loss,\n","        'train_channelwise_metrics': channelwise_metrics['train'],\n","        'val_channelwise_metrics': channelwise_metrics['val'],\n","    }\n","\n","    if test_loss is not None:\n","        checkpoint['test_loss'] = test_loss\n","        checkpoint['test_channelwise_metrics'] = channelwise_metrics['test']\n","\n","    # Save the history (losses, PCCs, RMSEs, channel-wise metrics)\n","    if history:\n","        checkpoint['history'] = history\n","\n","    # Save curriculum schedule\n","    if curriculum_schedule:\n","        checkpoint['curriculum_schedule'] = curriculum_schedule\n","\n","    torch.save(checkpoint, filename)\n","    print(f\"Checkpoint saved for epoch {epoch + 1}\")\n","\n","\n","\n","def train_teacher_with_reconstruction(device, train_loader, val_loader, test_loader, learn_rate, epochs, model, filename, loss_function, reconstruction_epochs=5, optimizer=None, l1_lambda=None, train_from_last_epoch=False, curriculum_loader=None):\n","    model.to(device)\n","    criterion = loss_function\n","\n","    if optimizer is None:\n","        optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate)\n","\n","    # Initialize history lists for storing losses, pccs, and rmses\n","    train_losses, val_losses, test_losses = [], [], []\n","    train_pccs, val_pccs, test_pccs = [], [], []\n","    train_rmses, val_rmses, test_rmses = [], [], []\n","\n","    # Check for existing checkpoint to resume training\n","    last_epoch = 0\n","    checkpoint_path = f\"/content/MyDrive/MyDrive/models/{filename}/\"\n","\n","    if train_from_last_epoch and os.path.exists(checkpoint_path):\n","        # Load existing checkpoints if available\n","        checkpoints = [f for f in os.listdir(checkpoint_path) if f.endswith('.pth')]\n","        if checkpoints:\n","            checkpoints.sort(key=lambda x: int(x.split('_')[-1].split('.')[0]))  # Sort by epoch number\n","            latest_checkpoint = checkpoints[-1]\n","            print(f\"Loading model from checkpoint: {latest_checkpoint}\")\n","            checkpoint = torch.load(os.path.join(checkpoint_path, latest_checkpoint))\n","            model.load_state_dict(checkpoint['model_state_dict'])\n","            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","            last_epoch = checkpoint['epoch']  # Continue from the next epoch\n","\n","            # Load history\n","            train_losses = checkpoint['history']['train_losses']\n","            val_losses = checkpoint['history']['val_losses']\n","            test_losses = checkpoint['history']['test_losses']\n","            train_pccs = checkpoint['history']['train_pccs']\n","            val_pccs = checkpoint['history']['val_pccs']\n","            test_pccs = checkpoint['history']['test_pccs']\n","            train_rmses = checkpoint['history']['train_rmses']\n","            val_rmses = checkpoint['history']['val_rmses']\n","            test_rmses = checkpoint['history']['test_rmses']\n","        else:\n","            print(\"No checkpoints found, starting from scratch.\")\n","    else:\n","        print(\"Starting from scratch.\")\n","\n","    start_time = time.time()\n","    best_val_loss = float('inf')\n","    patience = 10\n","    patience_counter = 0\n","\n","    # Step 1: Pre-training Phase (Reconstruction)\n","    print(f\"Starting reconstruction phase for {reconstruction_epochs} epochs\")\n","    for epoch in tqdm(range(reconstruction_epochs), desc=\"Reconstruction Epoch\"):\n","        model.train()\n","        epoch_start_time = time.time()\n","        reconstruction_losses = []\n","\n","        # Train only on test set for reconstruction\n","        for i, (x_acc, x_gyr, x_emg, _) in enumerate(test_loader):\n","            optimizer.zero_grad()\n","\n","            # Forward pass in reconstruction mode\n","            reconstructed_acc, reconstructed_gyr, reconstructed_emg = model(x_acc.to(device), x_gyr.to(device), x_emg.to(device), predict_mode=False)\n","\n","            # Compute reconstruction loss\n","            loss = reconstruction_loss((reconstructed_acc, reconstructed_gyr, reconstructed_emg), (x_acc.to(device), x_gyr.to(device), x_emg.to(device)))\n","\n","            # Backpropagate the reconstruction loss\n","            loss.backward()\n","            optimizer.step()\n","\n","            reconstruction_losses.append(loss.item())\n","\n","        avg_reconstruction_loss = sum(reconstruction_losses) / len(reconstruction_losses)\n","        print(f\"Reconstruction Epoch {epoch + 1}/{reconstruction_epochs}, Loss: {avg_reconstruction_loss:.4f}, Time: {time.time() - epoch_start_time:.2f}s\")\n","\n","    # Step 2: Main Training Phase (Joint Prediction)\n","    print(\"Starting main training phase on training set.\")\n","    for epoch in range(last_epoch, epochs):\n","        epoch_start_time = time.time()\n","        model.train()\n","\n","        epoch_train_loss = 0.0\n","\n","        for i, (x_acc, x_gyr, target, x_emg) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{epochs} Training\")):\n","            optimizer.zero_grad()\n","\n","            # Forward pass in prediction mode\n","            output,_ = model(x_acc.to(device), x_gyr.to(device), x_emg.to(device), predict_mode=True)\n","\n","            # Compute prediction loss (e.g., MSE loss)\n","            loss = criterion(output, target.to(device).float())\n","\n","            # Apply L1 regularization if specified\n","            if l1_lambda is not None:\n","                l1_norm = sum(p.abs().sum() for p in model.parameters())\n","                total_loss = loss + l1_lambda * l1_norm\n","            else:\n","                total_loss = loss\n","\n","            # Backpropagate the prediction loss\n","            total_loss.backward()\n","            optimizer.step()\n","\n","            epoch_train_loss += loss.item()\n","\n","        avg_train_loss = epoch_train_loss / len(train_loader)\n","        train_losses.append(avg_train_loss)\n","\n","        # Validation Phase\n","        avg_val_loss, avg_val_pcc, avg_val_rmse = evaluate_model(device, model, val_loader, criterion)\n","        val_losses.append(avg_val_loss)\n","        val_pccs.append(np.mean(avg_val_pcc))\n","        val_rmses.append(np.mean(avg_val_rmse))\n","\n","        # Test Phase\n","        avg_test_loss, avg_test_pcc, avg_test_rmse = evaluate_model(device, model, test_loader, criterion)\n","        test_losses.append(avg_test_loss)\n","        test_pccs.append(np.mean(avg_test_pcc))\n","        test_rmses.append(np.mean(avg_test_rmse))\n","\n","        print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Test Loss: {avg_test_loss:.4f}\")\n","        print(f\"Train RMSE: {np.mean(avg_val_rmse):.4f}, Val RMSE: {np.mean(avg_val_rmse):.4f}, Test RMSE: {np.mean(avg_test_rmse):.4f}\")\n","\n","        # Early stopping logic\n","        if avg_val_loss < best_val_loss:\n","            best_val_loss = avg_val_loss\n","            torch.save(model.state_dict(), filename)\n","            patience_counter = 0\n","        else:\n","            patience_counter += 1\n","\n","        if patience_counter >= patience:\n","            print(f\"Stopping early after {epoch + 1} epochs due to lack of improvement.\")\n","            break\n","\n","    end_time = time.time()\n","    print(f\"Total training time: {end_time - start_time:.2f} seconds\")\n","\n","    print(f\"Loading best model from {filename}\")\n","    model.load_state_dict(torch.load(filename))\n","    model.eval()\n","\n","    return model, train_losses, val_losses, test_losses, train_pccs, val_pccs, test_pccs, train_rmses, val_rmses, test_rmses\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"9Eul1_WhMTqb","executionInfo":{"status":"ok","timestamp":1729749725570,"user_tz":240,"elapsed":21,"user":{"displayName":"Oliver Fritsche","userId":"15171898326940313848"}}},"outputs":[],"source":["# @title Helper Functions\n","\n","\n","# Function to create the teacher model with defaults from config\n","def create_teacher_model(input_acc, input_gyr, input_emg, base_weights_path=None, drop_prob=0.25, w=100):\n","    model = TeacherAutoencoder(input_acc, input_gyr, input_emg, drop_prob=drop_prob, w=w)\n","\n","    if base_weights_path:\n","        # Load the initial weights from the base model\n","        model.load_state_dict(torch.load(base_weights_path))\n","\n","    return model\n","\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"hyj0qzUqXL93","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3e164298-6807-440f-f8be-9f6579bb9fe4","executionInfo":{"status":"ok","timestamp":1729749758650,"user_tz":240,"elapsed":33100,"user":{"displayName":"Oliver Fritsche","userId":"15171898326940313848"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Running training with subject_1 as the test subject.\n","Model: TeacherModel_RMSELoss_test_subject_1_wl100_ol75_SSL_100reconstructepochs\n","Sharded data found at /content/datasets/dataset_wl100_ol75_train_2_3_4_5_6_7_8_9_10_11_12_13. Skipping resharding.\n","Sharded data found at /content/datasets/dataset_wl100_ol0_test_1. Skipping resharding.\n","Running model: TeacherModel_RMSELoss_test_subject_1_wl100_ol75_SSL_100reconstructepochs\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-9-c886609c5134>:78: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(f\"{model_name}\"))\n"]},{"output_type":"stream","name":"stdout","text":["Test Loss: 18.6703, Test PCC: 0.7370, Test RMSE: 18.0575\n","Running training with subject_2 as the test subject.\n","Model: TeacherModel_RMSELoss_test_subject_2_wl100_ol75_SSL_100reconstructepochs\n","Sharded data found at /content/datasets/dataset_wl100_ol75_train_1_3_4_5_6_7_8_9_10_11_12_13. Skipping resharding.\n","Sharded data found at /content/datasets/dataset_wl100_ol0_test_2. Skipping resharding.\n","Running model: TeacherModel_RMSELoss_test_subject_2_wl100_ol75_SSL_100reconstructepochs\n","Test Loss: 22.7719, Test PCC: 0.6791, Test RMSE: 21.1448\n","Running training with subject_3 as the test subject.\n","Model: TeacherModel_RMSELoss_test_subject_3_wl100_ol75_SSL_100reconstructepochs\n","Sharded data found at /content/datasets/dataset_wl100_ol75_train_1_2_4_5_6_7_8_9_10_11_12_13. Skipping resharding.\n","Sharded data found at /content/datasets/dataset_wl100_ol0_test_3. Skipping resharding.\n","Running model: TeacherModel_RMSELoss_test_subject_3_wl100_ol75_SSL_100reconstructepochs\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-9-c886609c5134>:78: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(f\"{model_name}\"))\n","<ipython-input-9-c886609c5134>:78: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(f\"{model_name}\"))\n"]},{"output_type":"stream","name":"stdout","text":["Test Loss: 19.3659, Test PCC: 0.7527, Test RMSE: 17.3741\n","Running training with subject_4 as the test subject.\n","Model: TeacherModel_RMSELoss_test_subject_4_wl100_ol75_SSL_100reconstructepochs\n","Sharded data found at /content/datasets/dataset_wl100_ol75_train_1_2_3_5_6_7_8_9_10_11_12_13. Skipping resharding.\n","Sharded data found at /content/datasets/dataset_wl100_ol0_test_4. Skipping resharding.\n","Running model: TeacherModel_RMSELoss_test_subject_4_wl100_ol75_SSL_100reconstructepochs\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-9-c886609c5134>:78: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(f\"{model_name}\"))\n"]},{"output_type":"stream","name":"stdout","text":["Test Loss: 16.9299, Test PCC: 0.7555, Test RMSE: 15.8570\n","Running training with subject_5 as the test subject.\n","Model: TeacherModel_RMSELoss_test_subject_5_wl100_ol75_SSL_100reconstructepochs\n","Sharded data found at /content/datasets/dataset_wl100_ol75_train_1_2_3_4_6_7_8_9_10_11_12_13. Skipping resharding.\n","Sharded data found at /content/datasets/dataset_wl100_ol0_test_5. Skipping resharding.\n","Running model: TeacherModel_RMSELoss_test_subject_5_wl100_ol75_SSL_100reconstructepochs\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-9-c886609c5134>:78: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(f\"{model_name}\"))\n"]},{"output_type":"stream","name":"stdout","text":["Test Loss: 20.8294, Test PCC: 0.6663, Test RMSE: 19.8664\n","Running training with subject_6 as the test subject.\n","Model: TeacherModel_RMSELoss_test_subject_6_wl100_ol75_SSL_100reconstructepochs\n","Sharded data found at /content/datasets/dataset_wl100_ol75_train_1_2_3_4_5_7_8_9_10_11_12_13. Skipping resharding.\n","Sharded data found at /content/datasets/dataset_wl100_ol0_test_6. Skipping resharding.\n","Running model: TeacherModel_RMSELoss_test_subject_6_wl100_ol75_SSL_100reconstructepochs\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-9-c886609c5134>:78: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(f\"{model_name}\"))\n"]},{"output_type":"stream","name":"stdout","text":["Test Loss: 13.3105, Test PCC: 0.8179, Test RMSE: 12.2166\n","Running training with subject_7 as the test subject.\n","Model: TeacherModel_RMSELoss_test_subject_7_wl100_ol75_SSL_100reconstructepochs\n","Sharded data found at /content/datasets/dataset_wl100_ol75_train_1_2_3_4_5_6_8_9_10_11_12_13. Skipping resharding.\n","Sharded data found at /content/datasets/dataset_wl100_ol0_test_7. Skipping resharding.\n","Running model: TeacherModel_RMSELoss_test_subject_7_wl100_ol75_SSL_100reconstructepochs\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-9-c886609c5134>:78: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(f\"{model_name}\"))\n"]},{"output_type":"stream","name":"stdout","text":["Test Loss: 14.4694, Test PCC: 0.7930, Test RMSE: 13.4065\n","Running training with subject_8 as the test subject.\n","Model: TeacherModel_RMSELoss_test_subject_8_wl100_ol75_SSL_100reconstructepochs\n","Sharded data found at /content/datasets/dataset_wl100_ol75_train_1_2_3_4_5_6_7_9_10_11_12_13. Skipping resharding.\n","Sharded data found at /content/datasets/dataset_wl100_ol0_test_8. Skipping resharding.\n","Running model: TeacherModel_RMSELoss_test_subject_8_wl100_ol75_SSL_100reconstructepochs\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-9-c886609c5134>:78: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(f\"{model_name}\"))\n"]},{"output_type":"stream","name":"stdout","text":["Test Loss: 12.2476, Test PCC: 0.7463, Test RMSE: 11.8326\n","Running training with subject_9 as the test subject.\n","Model: TeacherModel_RMSELoss_test_subject_9_wl100_ol75_SSL_100reconstructepochs\n","Sharded data found at /content/datasets/dataset_wl100_ol75_train_1_2_3_4_5_6_7_8_10_11_12_13. Skipping resharding.\n","Sharded data found at /content/datasets/dataset_wl100_ol0_test_9. Skipping resharding.\n","Running model: TeacherModel_RMSELoss_test_subject_9_wl100_ol75_SSL_100reconstructepochs\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-9-c886609c5134>:78: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(f\"{model_name}\"))\n"]},{"output_type":"stream","name":"stdout","text":["Test Loss: 9.7233, Test PCC: 0.8070, Test RMSE: 9.6055\n","Running training with subject_10 as the test subject.\n","Model: TeacherModel_RMSELoss_test_subject_10_wl100_ol75_SSL_100reconstructepochs\n","Sharded data found at /content/datasets/dataset_wl100_ol75_train_1_2_3_4_5_6_7_8_9_11_12_13. Skipping resharding.\n","Sharded data found at /content/datasets/dataset_wl100_ol0_test_10. Skipping resharding.\n","Running model: TeacherModel_RMSELoss_test_subject_10_wl100_ol75_SSL_100reconstructepochs\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-9-c886609c5134>:78: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(f\"{model_name}\"))\n"]},{"output_type":"stream","name":"stdout","text":["Test Loss: 16.2441, Test PCC: 0.7440, Test RMSE: 15.2480\n","Running training with subject_11 as the test subject.\n","Model: TeacherModel_RMSELoss_test_subject_11_wl100_ol75_SSL_100reconstructepochs\n","Sharded data found at /content/datasets/dataset_wl100_ol75_train_1_2_3_4_5_6_7_8_9_10_12_13. Skipping resharding.\n","Sharded data found at /content/datasets/dataset_wl100_ol0_test_11. Skipping resharding.\n","Running model: TeacherModel_RMSELoss_test_subject_11_wl100_ol75_SSL_100reconstructepochs\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-9-c886609c5134>:78: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(f\"{model_name}\"))\n"]},{"output_type":"stream","name":"stdout","text":["Test Loss: 14.1028, Test PCC: 0.7693, Test RMSE: 13.3255\n","Running training with subject_12 as the test subject.\n","Model: TeacherModel_RMSELoss_test_subject_12_wl100_ol75_SSL_100reconstructepochs\n","Sharded data found at /content/datasets/dataset_wl100_ol75_train_1_2_3_4_5_6_7_8_9_10_11_13. Skipping resharding.\n","Sharded data found at /content/datasets/dataset_wl100_ol0_test_12. Skipping resharding.\n","Running model: TeacherModel_RMSELoss_test_subject_12_wl100_ol75_SSL_100reconstructepochs\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-9-c886609c5134>:78: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(f\"{model_name}\"))\n"]},{"output_type":"stream","name":"stdout","text":["Test Loss: 12.9677, Test PCC: 0.8143, Test RMSE: 12.3122\n","Running training with subject_13 as the test subject.\n","Model: TeacherModel_RMSELoss_test_subject_13_wl100_ol75_SSL_100reconstructepochs\n","Sharded data found at /content/datasets/dataset_wl100_ol75_train_1_2_3_4_5_6_7_8_9_10_11_12. Skipping resharding.\n","Sharded data found at /content/datasets/dataset_wl100_ol0_test_13. Skipping resharding.\n","Running model: TeacherModel_RMSELoss_test_subject_13_wl100_ol75_SSL_100reconstructepochs\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-9-c886609c5134>:78: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(f\"{model_name}\"))\n"]},{"output_type":"stream","name":"stdout","text":["Test Loss: 17.7708, Test PCC: 0.7594, Test RMSE: 16.4885\n","Average of best RMSEs across all subjects: 15.1335\n"]}],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import h5py\n","from tqdm.notebook import tqdm\n","import pandas as pd\n","import csv\n","\n","all_subjects= [f\"subject_{x}\" for x in range(1,14)]\n","input_acc, input_gyr, input_emg = 18,18,3\n","batch_size = 64\n","\n","train_flag = False\n","# Placeholder for storing best RMSEs\n","best_rmse_per_subject = []\n","best_pcc_per_subject = []\n","for test_subject in all_subjects:\n","    print(f\"Running training with {test_subject} as the test subject.\")\n","\n","    # Set up the training subjects (all except the test subject)\n","    train_subjects = [subject for subject in all_subjects if subject != test_subject]\n","\n","    model_name = f'TeacherModel_RMSELoss_test_{test_subject}_wl{100}_ol{75}_SSL_100reconstructepochs'\n","    print(f\"Model: {model_name}\")\n","\n","    # Load the model configuration and data loaders\n","    model_config = {\n","        'model': create_teacher_model(input_acc, input_gyr, input_emg, w=100),\n","        'loss': RMSELoss(),\n","        'loaders': create_base_data_loaders(\n","            config=config,\n","            train_subjects=train_subjects,\n","            test_subjects=[test_subject],\n","            window_length=100,\n","            window_overlap=75,\n","            batch_size=batch_size\n","        ),\n","        'epochs': 10,  # Running for 10 epochs as requested\n","        'use_curriculum': False,\n","        'reconstruction_epochs': 100\n","    }\n","\n","    model = model_config['model']\n","    loss_function = model_config['loss']\n","    epochs = model_config.get(\"epochs\", 10)\n","    device = model_config.get(\"device\", torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n","    learn_rate = model_config.get(\"learn_rate\", 0.001)\n","    use_curriculum = model_config.get(\"use_curriculum\", False)\n","    reconstruction_epochs = model_config.get(\"reconstruction_epochs\", 5)\n","\n","    optimizer = model_config.get(\"optimizer\", None)\n","    l1_lambda = model_config.get(\"l1_lambda\", None)\n","\n","    print(f\"Running model: {model_name}\")\n","\n","    # Unpack the static loaders tuple (train_loader, val_loader, test_loader)\n","    train_loader, val_loader, test_loader = model_config['loaders']\n","\n","    if train_flag:\n","      # Train the model and save only the best based on validation loss\n","      model, train_losses, val_losses, test_losses, train_pccs, val_pccs, test_pccs, train_rmses, val_rmses, test_rmses = train_teacher_with_reconstruction(\n","          device=device,\n","          train_loader=train_loader,\n","          val_loader=val_loader,\n","          test_loader=test_loader,\n","          learn_rate=learn_rate,\n","          epochs=epochs,\n","          model=model,\n","          filename=model_name,\n","          loss_function=loss_function,\n","          optimizer=optimizer,\n","          l1_lambda=l1_lambda,\n","          reconstruction_epochs=reconstruction_epochs,\n","          train_from_last_epoch=False\n","      )\n","    else:\n","      #load filename as model\n","      model.load_state_dict(torch.load(f\"{model_name}\"))\n","      model.to(device)\n","      model.eval()\n","\n","     #run model on test set and record result\n","    test_loss, test_pcc, test_rmse = evaluate_model(device, model, test_loader, loss_function)\n","    print(f\"Test Loss: {test_loss:.4f}, Test PCC: {np.mean(test_pcc):.4f}, Test RMSE: {np.mean(test_rmse):.4f}\")\n","    best_rmse_per_subject.append(np.mean(test_rmse))\n","    best_pcc_per_subject.append(np.mean(test_pcc))\n","\n","\n","# Compute the average of the best RMSEs across all subjects\n","average_best_rmse = np.mean(best_rmse_per_subject)\n","print(f\"Average of best RMSEs across all subjects: {average_best_rmse:.4f}\")\n"]},{"cell_type":"code","source":["average_best_rmse = np.mean(best_rmse_per_subject)\n","average_best_pcc = np.mean(best_pcc_per_subject)\n","print(f\"Average of best RMSEs across all subjects: {average_best_rmse:.4f}\")\n","print(f\"Average of best PCCs across all subjects: {average_best_pcc:.4f}\")\n","print(best_rmse_per_subject)\n","print(best_pcc_per_subject)"],"metadata":{"id":"wzvnYVL7WXQd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729749758650,"user_tz":240,"elapsed":12,"user":{"displayName":"Oliver Fritsche","userId":"15171898326940313848"}},"outputId":"d5e65dbc-0acb-4df0-8293-892ee6b5d2f9"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Average of best RMSEs across all subjects: 15.1335\n","Average of best PCCs across all subjects: 0.7571\n","[18.05746563275655, 21.144810994466145, 17.3741042415301, 15.856963515281677, 19.86643213033676, 12.21656366189321, 13.406468669573465, 11.832554558912912, 9.605545977751413, 15.248006025950113, 13.32548995812734, 12.312191327412924, 16.488526940345764]\n","[0.7369937107505221, 0.6791006807982889, 0.7526694093357774, 0.755504991048138, 0.6663264997406361, 0.8179068423302223, 0.7930335990666654, 0.7463177592854033, 0.8069757498245913, 0.7439733696110817, 0.7693329698630134, 0.8142728381471253, 0.7593542461223803]\n"]}]},{"cell_type":"code","source":["import os\n","import zipfile\n","from datetime import datetime\n","\n","notebook_name = 'regression_benchmark_ssl_100reconstructepochs'\n","\n","# Create a timestamped folder name based on the notebook name\n","timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","folder_name = f\"{notebook_name}_checkpoints_{timestamp}\"\n","\n","# Make sure the folder exists\n","os.makedirs(folder_name, exist_ok=True)\n","\n","checkpoint_dir = '.'\n","\n","# Zip all checkpoint files and save in the new folder\n","zip_filename = f\"{folder_name}.zip\"\n","with zipfile.ZipFile(zip_filename, 'w') as zipf:\n","    # List files only in the current directory (no subfolders)\n","    for file in os.listdir(checkpoint_dir):\n","        if \"TeacherModel\" in str(file):\n","          file_path = os.path.join(checkpoint_dir, file)\n","          zipf.write(file_path, os.path.relpath(file_path, checkpoint_dir))\n","          print(f\"Checkpoint {file} has been added to the zip file.\")\n","print(f\"All checkpoints have been zipped and saved as {zip_filename}.\")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"msZa5eELH3Qk","executionInfo":{"status":"ok","timestamp":1729749759363,"user_tz":240,"elapsed":723,"user":{"displayName":"Oliver Fritsche","userId":"15171898326940313848"}},"outputId":"f91d796f-02aa-491e-897d-45ec4b31bf4d"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Checkpoint TeacherModel_RMSELoss_test_subject_7_wl100_ol75_SSL_100reconstructepochs has been added to the zip file.\n","Checkpoint TeacherModel_RMSELoss_test_subject_2_wl100_ol75_SSL_100reconstructepochs has been added to the zip file.\n","Checkpoint TeacherModel_RMSELoss_test_subject_5_wl100_ol75_SSL_100reconstructepochs has been added to the zip file.\n","Checkpoint TeacherModel_RMSELoss_test_subject_12_wl100_ol75_SSL_100reconstructepochs has been added to the zip file.\n","Checkpoint TeacherModel_RMSELoss_test_subject_9_wl100_ol75_SSL_100reconstructepochs has been added to the zip file.\n","Checkpoint TeacherModel_RMSELoss_test_subject_6_wl100_ol75_SSL_100reconstructepochs has been added to the zip file.\n","Checkpoint TeacherModel_RMSELoss_test_subject_4_wl100_ol75_SSL_100reconstructepochs has been added to the zip file.\n","Checkpoint TeacherModel_RMSELoss_test_subject_1_wl100_ol75_SSL_100reconstructepochs has been added to the zip file.\n","Checkpoint TeacherModel_RMSELoss_test_subject_8_wl100_ol75_SSL_100reconstructepochs has been added to the zip file.\n","Checkpoint TeacherModel_RMSELoss_test_subject_3_wl100_ol75_SSL_100reconstructepochs has been added to the zip file.\n","Checkpoint TeacherModel_RMSELoss_test_subject_13_wl100_ol75_SSL_100reconstructepochs has been added to the zip file.\n","Checkpoint TeacherModel_RMSELoss_test_subject_11_wl100_ol75_SSL_100reconstructepochs has been added to the zip file.\n","Checkpoint TeacherModel_RMSELoss_test_subject_10_wl100_ol75_SSL_100reconstructepochs has been added to the zip file.\n","All checkpoints have been zipped and saved as regression_benchmark_ssl_100reconstructepochs_checkpoints_20241024_060238.zip.\n"]}]},{"cell_type":"code","source":["# Download the zip file to your local machine\n","from google.colab import files\n","files.download(zip_filename)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"YR-OttPA_sA5","executionInfo":{"status":"ok","timestamp":1729749903755,"user_tz":240,"elapsed":454,"user":{"displayName":"Oliver Fritsche","userId":"15171898326940313848"}},"outputId":"6c4dfa43-e6ec-4bab-e1f1-dc6ee2e99356"},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_8f344ac5-d0e7-4e31-851a-48b9e7e48468\", \"regression_benchmark_ssl_100reconstructepochs_checkpoints_20241024_060238.zip\", 298993098)"]},"metadata":{}}]},{"cell_type":"code","source":["#copy zip file into google drive\n","import shutil\n","\n","destination_path = '/content/MyDrive/MyDrive/models'\n","\n","shutil.copy(zip_filename, destination_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mSVy5w8bAcgZ","executionInfo":{"status":"ok","timestamp":1729750377606,"user_tz":240,"elapsed":1168,"user":{"displayName":"Oliver Fritsche","userId":"15171898326940313848"}},"outputId":"429ec5e5-21a4-4fb2-a9dd-5cb3793b5382"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/MyDrive/MyDrive/models/regression_benchmark_ssl_100reconstructepochs_checkpoints_20241024_060238.zip'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":[],"metadata":{"id":"S8GbmrPxKB2o"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"19fVFltPHfe1e4_2G7RNceiftD7CaCzsg","timestamp":1729725781398},{"file_id":"1OrqOEtMnWVFcSotx3oRVP7Kb6nAp5gKk","timestamp":1729722003337},{"file_id":"1ca6IWhaCNijsFxrjbz9MR7LAKEU5B2hT","timestamp":1729719161382},{"file_id":"1GG-T-9Pn3nWxXXDd3VzbjBUDDVBdquPe","timestamp":1727255073654},{"file_id":"1Odo2lxio-f6aVjKEBW4pGlFhEhRFuhig","timestamp":1726983228854},{"file_id":"1AKDQttSbC8SMdITVTIjya06gkxYOJ_NR","timestamp":1726706052358},{"file_id":"14JnySuUfKLfxc10Cw-McYCVHrbCl8e6x","timestamp":1726654334086},{"file_id":"1E6EBrFXKUIM8p9LD1XD4qYq-FnhvYnPz","timestamp":1726443626748},{"file_id":"1IYYQsxrg4uHErJuoV8MFIy_W67h0kWYl","timestamp":1726192532263},{"file_id":"11wbW9XhB8W7ViaUbAd6at_S5bG1-httV","timestamp":1726140420655},{"file_id":"12OM6Fm5sj9mUIEB3bktkaIeGsmM9Zqax","timestamp":1726107191041},{"file_id":"1Gu2Mego9pAJ1jH7ReLQef58Qo09Crmvu","timestamp":1725923231392},{"file_id":"1rdHb4TuCnnIDmoPaIx_xt1QlqeoqZ3aJ","timestamp":1725867609654},{"file_id":"1zVQFZK4F4nFC3rAsfc5f276kkLKyabA7","timestamp":1725770443175},{"file_id":"1_srYfBgGy8FQIMSohL9HL3Ac4ZZfvPVF","timestamp":1722559818032},{"file_id":"1ueeVtfayoqaNooAbjpcCBoKOWg7UmxAp","timestamp":1722359381849},{"file_id":"1ryl9H3tW6u9DyNInb-iS82rOZ4anjgZt","timestamp":1722295666388},{"file_id":"1lyKGsrpoLMhWE9Qz6A7qFZ5-o3fVuSVw","timestamp":1722291006477},{"file_id":"1JhajboXIAvcWgKNCN4Ljlg-Ebih6rbi3","timestamp":1722268029267},{"file_id":"1-tWEKDHgFp0R-NvBdAJIIFHZKc6185I4","timestamp":1722201240061},{"file_id":"1r91HidleatpLF4x2rdc9DnxWyb-U9exV","timestamp":1722197547794},{"file_id":"1sWKusmF7ocIZanW6vcld-Mr6bzERe-kb","timestamp":1722196228475},{"file_id":"1nzXq_89_RbuU-OR3LFr-idc_Gl8aypPt","timestamp":1722195060257},{"file_id":"1v8w64kwmH2zehSmEaUGsLZqJNEwecL-i","timestamp":1722185530003},{"file_id":"1QuAo2poyCHl3DFfE8Wrj9OnfDzv5HgpR","timestamp":1722181752384},{"file_id":"11qGVlcaE5KShLP8boMFZU_pIAYHJv2N1","timestamp":1722113928372},{"file_id":"1fzC0avZyr80RIwPOYEeAtJIlD_xB0-zv","timestamp":1722100536152}],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":0}